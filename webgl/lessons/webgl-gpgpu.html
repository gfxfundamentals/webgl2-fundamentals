<!DOCTYPE html>
<!-- this file is auto-generated from webgl/lessons/webgl-gpgpu.md. Do not edited directly -->
<!--
Copyright 2021, GFXFundamentals.
All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are
met:

*   Redistributions of source code must retain the above copyright
    notice, this list of conditions and the following disclaimer.

*   Redistributions in binary form must reproduce the above
    copyright notice, this list of conditions and the following disclaimer
    in the documentation and/or other materials provided with the
    distribution.

*   Neither the name of GFXFundamentals. nor the names of his
    contributors may be used to endorse or promote products derived from
    this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-->
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="How to do general computing with WebGL">
<meta name="keywords" content="webgl webgl2 graphics">
<meta name="thumbnail" content="https://webgl2fundamentals.org/webgl/lessons/screenshots/webgl-gpgpu_en.jpg">

<meta property="og:title" content="WebGL2 GPGPU">
<meta property="og:type" content="website">
<meta property="og:image" content="https://webgl2fundamentals.org/webgl/lessons/screenshots/webgl-gpgpu_en.jpg">
<meta property="og:description" content="How to do general computing with WebGL">
<meta property="og:url" content="https://webgl2fundamentals.org/webgl/lessons/webgl-gpgpu.html">

<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@greggman">
<meta name="twitter:creator" content="@greggman">
<meta name="twitter:domain" content="webgl2fundamentals.org">
<meta name="twitter:title" content="WebGL2 GPGPU">
<meta name="twitter:url" content="https://webgl2fundamentals.org/webgl/lessons/webgl-gpgpu.html">
<meta name="twitter:description" content="How to do general computing with WebGL">
<meta name="twitter:image:src" content="https://webgl2fundamentals.org/webgl/lessons/screenshots/webgl-gpgpu_en.jpg">

<script type="application/ld+json">
{
  "@context":"https://schema.org",
  "@graph":[
    {
      "@type":"WebSite",
      "@id":"https://webgl2fundamentals.org/#website",
      "url":"https://webgl2fundamentals.org/",
      "name":"Webgl2Fundamentals"
    },
    {
      "@type":"ImageObject",
      "@id":"https://webgl2fundamentals.org/webgl/lessons/webgl-gpgpu.html#primaryimage",
      "url":"https://webgl2fundamentals.org/webgl/lessons/screenshots/webgl-gpgpu_en.jpg",
      "width":1200,
      "height":630
    },
    {
      "@type":"WebPage",
      "@id":"https://webgl2fundamentals.org/webgl/lessons/webgl-gpgpu.html#webpage",
      "url":"https://webgl2fundamentals.org/webgl/lessons/webgl-gpgpu.html",
      "inLanguage":"en",
      "name":"WebGL2 GPGPU",
      "keywords":"webgl webgl2 graphics programming",
      "isPartOf":{
        "@id":"https://webgl2fundamentals.org/#website"
      },
      "primaryImageOfPage":{
        "@id":"https://webgl2fundamentals.org/webgl/lessons/webgl-gpgpu.html#primaryimage"
      }
    }
  ]
}
</script>


<title>WebGL2 GPGPU</title>
<link href="/webgl/lessons/resources/webgl2fundamentals-icon.png" rel="shortcut icon" type="image/png">
<link rel="stylesheet" href="/webgl/lessons/lang.css">
<link rel="stylesheet" href="/webgl/lessons/resources/lesson.css">

  <link rel="alternate" hreflang="en" href="https://webglfundamentals.org/webgl/lessons/webgl-gpgpu.html">
  <link rel="alternate" hreflang="de" href="https://webglfundamentals.org/webgl/lessons/de/webgl-gpgpu.html">
  <link rel="alternate" hreflang="ja" href="https://webglfundamentals.org/webgl/lessons/ja/webgl-gpgpu.html">
  <link rel="alternate" hreflang="ko" href="https://webglfundamentals.org/webgl/lessons/ko/webgl-gpgpu.html">
  <link rel="alternate" hreflang="pt-br" href="https://webglfundamentals.org/webgl/lessons/pt-br/webgl-gpgpu.html">
  <link rel="alternate" hreflang="ru" href="https://webglfundamentals.org/webgl/lessons/ru/webgl-gpgpu.html">
  <link rel="alternate" hreflang="zh_cn" href="https://webglfundamentals.org/webgl/lessons/zh_cn/webgl-gpgpu.html">




</head>
<body>
<div class="webgl_navbar">
  <div>
    <select class="language">
    <option value="/webgl/lessons/webgl-gpgpu.html" selected>English</a>
    <option value="/webgl/lessons/de/webgl-gpgpu.html" >Deutsch</a>
    <option value="/webgl/lessons/ja/webgl-gpgpu.html" >日本語</a>
    <option value="/webgl/lessons/ko/webgl-gpgpu.html" >한국어</a>
    <option value="/webgl/lessons/pt-br/webgl-gpgpu.html" >Português Brasileiro</a>
    <option value="/webgl/lessons/ru/webgl-gpgpu.html" >Русский</a>
    <option value="/webgl/lessons/zh_cn/webgl-gpgpu.html" >简体中文</a>
</select>


    <a href="#toc">Table of Contents</a>
    <input type="search" placeholder="?" id="search">
  </div>
</div>
<div class="webgl_header">
  <h1><a href="/">WebGL2Fundamentals.org</a></h1>
<style>
#forkongithub>div {
    background: #000;
    color: #fff;
    font-family: arial,sans-serif;
    text-align: center;
    font-weight: bold;
    padding: 5px 40px;
    font-size: 0.9rem;
    line-height: 1.3rem;
    position: relative;
    transition: 0.5s;
    display: block;
    width: 400px;
    position: absolute;
    top: 0;
    right: 0;
    transform: translateX(200px) rotate(45deg) translate(10px,70px);
    box-shadow: 4px 4px 10px rgba(0,0,0,0.8);
    pointer-events: auto;
}
#forkongithub a {
  text-decoration: none;
  color: #fff;
}
#forkongithub>div:hover {
    background: #c11;
    color: #fff;
}
#forkongithub .contributors {
  font-size: 0.75rem;
  background: rgba(255,255,255,0.2);
  line-height: 1.2;
  padding: 0.1em;
}
#forkongithub>div::before,#forkongithub>div::after {
    content: "";
    width: 100%;
    display: block;
    position: absolute;
    top: 1px;
    left: 0;
    height: 1px;
    background: #fff;
}
#forkongithub>div::after {
    bottom: 1px;
    top: auto;
}

#forkongithub{
    z-index: 9999;
    /* needed for firefox */
    overflow: hidden;
    width: 300px;
    height: 300px;
    position: absolute;
    right: 0;
    top: 0;
    pointer-events: none;
}
#forkongithub svg{
  width: 1em;
  height: 1em;
  vertical-align: middle;
}
#forkongithub img {
  width: 1em;
  height: 1em;
  border-radius: 100%;
  vertical-align: middle;
}

@media (max-width: 900px) {
    #forkongithub>div {
        line-height: 1.2rem;
    }
}
@media (max-width: 700px) {
  #forkongithub {
    display: none;
  }
}
@media (max-width: 410px) {
    #forkongithub>div {
        font-size: 0.7rem;
        transform: translateX(150px) rotate(45deg) translate(20px,40px);
    }
}

</style>
<div id="forkongithub"><div><div><a href="https://github.com/gfxfundamentals/webgl2-fundamentals">Fix, Fork, Contribute <?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<svg width="100%" height="100%" viewBox="0 0 136 133" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" xmlns:serif="http://www.serif.com/" style="fill-rule:evenodd;clip-rule:evenodd;stroke-linejoin:round;stroke-miterlimit:2;">
    <g transform="matrix(3.92891,0,0,3.92891,67.867,129.125)">
        <path d="M0,-31.904C-8.995,-31.904 -16.288,-24.611 -16.288,-15.614C-16.288,-8.417 -11.621,-2.312 -5.148,-0.157C-4.333,-0.008 -4.036,-0.511 -4.036,-0.943C-4.036,-1.329 -4.05,-2.354 -4.058,-3.713C-8.589,-2.729 -9.545,-5.897 -9.545,-5.897C-10.286,-7.779 -11.354,-8.28 -11.354,-8.28C-12.833,-9.29 -11.242,-9.27 -11.242,-9.27C-9.607,-9.155 -8.747,-7.591 -8.747,-7.591C-7.294,-5.102 -4.934,-5.821 -4.006,-6.238C-3.858,-7.29 -3.438,-8.008 -2.972,-8.415C-6.589,-8.826 -10.392,-10.224 -10.392,-16.466C-10.392,-18.244 -9.757,-19.698 -8.715,-20.837C-8.883,-21.249 -9.442,-22.905 -8.556,-25.148C-8.556,-25.148 -7.188,-25.586 -4.076,-23.478C-2.777,-23.84 -1.383,-24.02 0.002,-24.026C1.385,-24.02 2.779,-23.84 4.08,-23.478C7.19,-25.586 8.555,-25.148 8.555,-25.148C9.444,-22.905 8.885,-21.249 8.717,-20.837C9.761,-19.698 10.392,-18.244 10.392,-16.466C10.392,-10.208 6.583,-8.831 2.954,-8.428C3.539,-7.925 4.06,-6.931 4.06,-5.411C4.06,-3.234 4.04,-1.477 4.04,-0.943C4.04,-0.507 4.333,0 5.16,-0.159C11.628,-2.318 16.291,-8.419 16.291,-15.614C16.291,-24.611 8.997,-31.904 0,-31.904" style="fill:white;"/>
    </g>
</svg>
</a></div></div></div>

</div>


<div class="container">
  <div class="lesson-title">
    <h1>WebGL2 GPGPU</h1>
  </div>
  <div class="lesson">
    <div class="lesson-main">
      <p>GPGPU is “General Purpose” GPU and means using the GPU for something
other than drawing pixels.</p>
<p>The basic realization to understanding GPGPU in WebGL is that a texture
is not an image, it’s a 2D array of values. In <a href="webgl-3d-textures.html">the article on textures</a>
we covered reading from a texture. In <a href="webgl-render-to-texture.html">the article on rendering to a texture</a>
we covered writing to a texture. So, if realizing a texture is a 2D array of values
we can say that we have really described a way to read from and write to 2D arrays.
Similarly a buffer is not just positions, normals, texture coordinates, and colors.
That data could be anything. Velocities, masses, stock prices, etc.
Creatively using that knowledge to do math, that is the essence of GPGPU in WebGL.</p>
<h2 id="first-lets-do-it-with-textures">First let’s do it with textures</h2>
<p>In JavaScript there is the <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map"><code class="notranslate" translate="no">Array.prototype.map</code></a> function which given an array calls a function on each element</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">function multBy2(v) {
  return v * 2;
}

const src = [1, 2, 3, 4, 5, 6];
const dst = src.map(multBy2);

// dst is now [2, 4, 6, 8, 10, 12];
</code></pre>
<p>You can consider <code class="notranslate" translate="no">multBy2</code> a shader and <code class="notranslate" translate="no">map</code> similar to calling <code class="notranslate" translate="no">gl.drawArrays</code> or <code class="notranslate" translate="no">gl.drawElements</code>.
Some differences.</p>
<h2 id="shaders-dont-generate-a-new-array-you-have-to-provide-one">Shaders don’t generate a new array, you have to provide one</h2>
<p>We can simulate that by making our own map function</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">function multBy2(v) {
  return v * 2;
}

+function mapSrcToDst(src, fn, dst) {
+  for (let i = 0; i &lt; src.length; ++i) {
+    dst[i] = fn(src[i]);
+  }
+}

const src = [1, 2, 3, 4, 5, 6];
-const dst = src.map(multBy2);
+const dst = new Array(6);    // to simulate that in WebGL we have to allocate a texture
+mapSrcToDst(src, multBy2, dst);

// dst is now [2, 4, 6, 8, 10, 12];
</code></pre>
<h2 id="shaders-dont-return-a-value-they-set-an-out-variable">Shaders don’t return a value they set an <code class="notranslate" translate="no">out</code> variable</h2>
<p>That’s pretty easy to simulate</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">+let outColor;

function multBy2(v) {
-  return v * 2;
+  outColor = v * 2;
}

function mapSrcToDst(src, fn, dst) {
  for (let i = 0; i &lt; src.length; ++i) {
-    dst[i] = fn(src[i]);
+    fn(src[i]);
+    dst[i] = outColor;
  }
}

const src = [1, 2, 3, 4, 5, 6];
const dst = new Array(6);    // to simulate that in WebGL we have to allocate a texture
mapSrcToDst(src, multBy2, dst);

// dst is now [2, 4, 6, 8, 10, 12];
</code></pre>
<h2 id="shaders-are-destination-based-not-source-based">Shaders are destination based, not source based.</h2>
<p>In other words, they loop over the destination and ask “what value should I put here”</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">let outColor;

function multBy2(src) {
-  outColor = v * 2;
+  return function(i) {
+    outColor = src[i] * 2;
+  }
}

-function mapSrcToDst(src, fn, dst) {
-  for (let i = 0; i &lt; src.length; ++i) {
-    fn(src[i]);
+function mapDst(dst, fn) {
+  for (let i = 0; i &lt; dst.length; ++i) {    
+    fn(i);
    dst[i] = outColor;
  }
}

const src = [1, 2, 3, 4, 5, 6];
const dst = new Array(6);    // to simulate that in WebGL we have to allocate a texture
mapDst(dst, multBy2(src));

// dst is now [2, 4, 6, 8, 10, 12];
</code></pre>
<h2 id="in-webgl-the-index-or-id-of-the-pixel-whose-value-youre-being-asked-to-provide-is-called-gl_fragcoord">In WebGL the index or ID of the pixel whose value you’re being asked to provide is called <code class="notranslate" translate="no">gl_FragCoord</code></h2>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">let outColor;
+let gl_FragCoord;

function multBy2(src) {
-  return function(i) {
-    outColor = src[i] * 2;
+  return function() {
+    outColor = src[gl_FragCoord] * 2;
  }
}

function mapDst(dst, fn) {
  for (let i = 0; i &lt; dst.length; ++i) {    
-    fn(i);
+    gl_FragCoord = i;
+    fn();
    dst[i] = outColor;
  }
}

const src = [1, 2, 3, 4, 5, 6];
const dst = new Array(6);    // to simulate that in WebGL we have to allocate a texture
mapDst(dst, multBy2(src));

// dst is now [2, 4, 6, 8, 10, 12];
</code></pre>
<h2 id="in-webgl-textures-are-2d-arrays">In WebGL textures are 2D arrays.</h2>
<p>Let’s assume our <code class="notranslate" translate="no">dst</code> array represents a 3x2 texture</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">let outColor;
let gl_FragCoord;

function multBy2(src, across) {
  return function() {
-    outColor = src[gl_FragCoord] * 2;
+    outColor = src[gl_FragCoord.y * across + gl_FragCoord.x] * 2;
  }
}

-function mapDst(dst, fn) {
-  for (let i = 0; i &lt; dst.length; ++i) {    
-    gl_FragCoord = i;
-    fn();
-    dst[i] = outColor;
-  }
-}
function mapDst(dst, across, up, fn) {
  for (let y = 0; y &lt; up; ++y) {
    for (let x = 0; x &lt; across; ++x) {
      gl_FragCoord = {x, y};
      fn();
      dst[y * across + x] = outColor;
    }
  }
}

const src = [1, 2, 3, 4, 5, 6];
const dst = new Array(6);    // to simulate that in WebGL we have to allocate a texture
mapDst(dst, 3, 2, multBy2(src, 3));

// dst is now [2, 4, 6, 8, 10, 12];
</code></pre>
<p>And we could keep going. I’m hoping the examples above helps you see that GPGPU in WebGL
is pretty simple conceptually. Let’s actually do the above in WebGL.</p>
<p>To understand the following code you will, at a minimum, need to have read
<a href="webgl-fundamentals.html">the article on fundamentals</a>, probably the article on
<a href="webgl-how-it-works.html">How It Works</a>, the article on <a href="webgl-shaders-and-glsl.html">GLSL</a>
and <a href="webgl-3d-textures.html">the article on textures</a>.</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">const vs = `#version 300 es
in vec4 position;
void main() {
  gl_Position = position;
}
`;

const fs = `#version 300 es
precision highp float;

uniform sampler2D srcTex;

out vec4 outColor;

void main() {
  ivec2 texelCoord = ivec2(gl_FragCoord.xy);
  vec4 value = texelFetch(srcTex, texelCoord, 0);  // 0 = mip level 0
  outColor = value * 2.0;
}
`;

const dstWidth = 3;
const dstHeight = 2;

// make a 3x2 canvas for 6 results
const canvas = document.createElement('canvas');
canvas.width = dstWidth;
canvas.height = dstHeight;

const gl = canvas.getContext('webgl2');

const program = webglUtils.createProgramFromSources(gl, [vs, fs]);
const positionLoc = gl.getAttribLocation(program, 'position');
const srcTexLoc = gl.getUniformLocation(program, 'srcTex');

// setup a full canvas clip space quad
const buffer = gl.createBuffer();
gl.bindBuffer(gl.ARRAY_BUFFER, buffer);
gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([
  -1, -1,
   1, -1,
  -1,  1,
  -1,  1,
   1, -1,
   1,  1,
]), gl.STATIC_DRAW);

// Create a vertex array object (attribute state)
const vao = gl.createVertexArray();
gl.bindVertexArray(vao);

// setup our attributes to tell WebGL how to pull
// the data from the buffer above to the position attribute
gl.enableVertexAttribArray(positionLoc);
gl.vertexAttribPointer(
    positionLoc,
    2,         // size (num components)
    gl.FLOAT,  // type of data in buffer
    false,     // normalize
    0,         // stride (0 = auto)
    0,         // offset
);

// create our source texture
const srcWidth = 3;
const srcHeight = 2;
const tex = gl.createTexture();
gl.bindTexture(gl.TEXTURE_2D, tex);
gl.pixelStorei(gl.UNPACK_ALIGNMENT, 1); // see https://webglfundamentals.org/webgl/lessons/webgl-data-textures.html
gl.texImage2D(
    gl.TEXTURE_2D,
    0,                // mip level
    gl.R8,            // internal format
    srcWidth,
    srcHeight,
    0,                // border
    gl.RED,           // format
    gl.UNSIGNED_BYTE, // type
    new Uint8Array([
      1, 2, 3,
      4, 5, 6,
    ]));
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST);
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.NEAREST);
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);

gl.useProgram(program);
gl.uniform1i(srcTexLoc, 0);  // tell the shader the src texture is on texture unit 0

gl.drawArrays(gl.TRIANGLES, 0, 6);  // draw 2 triangles (6 vertices)

// get the result
const results = new Uint8Array(dstWidth * dstHeight * 4);
gl.readPixels(0, 0, dstWidth, dstHeight, gl.RGBA, gl.UNSIGNED_BYTE, results);

// print the results
for (let i = 0; i &lt; dstWidth * dstHeight; ++i) {
  log(results[i * 4]);
}
</code></pre>
<p>and here it is running</p>
<p><div class="webgl_example_container">
  <iframe class="webgl_example" style=" " src="/webgl/resources/editor.html?url=/webgl/lessons/..%2Fwebgl-gpgpu-mult-by-2.html"></iframe>
  <a class="webgl_center" href="/webgl/lessons/../webgl-gpgpu-mult-by-2.html" target="_blank">click here to open in a separate window</a>
</div>

</p>
<p>Some notes about the code above.</p>
<ul>
<li>
<p>We draw a clip space -1 to +1 quad.</p>
<p>We create vertices for a -1 to +1 quad from 2 triangles. This means, assuming the viewport
is set correctly, we’ll draw all the pixels in the destination. In other words we’ll ask
our shader to generate a value for every element in the result array. That array in
this case is the canvas itself.</p>
</li>
<li>
<p><code class="notranslate" translate="no">texelFetch</code> is a texture function that looks up a single texel from a texture.</p>
<p>It takes 3 parameters. The sampler, an integer based texel coordinate, and mip level.
<code class="notranslate" translate="no">gl_FragCoord</code> is a vec2, we need to turn it into an <code class="notranslate" translate="no">ivec2</code> to use it with
<code class="notranslate" translate="no">texelFetch</code>. There is no extra math to do here as long the source texture and
destination texture are the same size which in this case they are.</p>
</li>
<li>
<p>Our Shader is writing 4 values per pixel</p>
<p>In this particular case this affects how we read the output. We ask for <code class="notranslate" translate="no">RGBA/UNSIGNED_BYTE</code>
from <code class="notranslate" translate="no">readPixels</code> <a href="webgl-readpixels.html">because other format/type combinations are not supported</a>.
So we have to look at every 4th value for our answer.</p>
<p>Note: It would be smart to try to take advantage of the fact that WebGL does 4 values at a time
to go even faster.</p>
</li>
<li>
<p>We use <code class="notranslate" translate="no">R8</code> as our texture’s internal format.</p>
<p>This means only the red channel from the texture has value from our data.</p>
</li>
<li>
<p>Both our input data and output data (the canvas) are <code class="notranslate" translate="no">UNSIGNED_BYTE</code> values</p>
<p>The means we can only pass in and get back integer values between 0 and 255.
We could use different formats for input by supplying a texture of a different format.
We could also try rendering to a texture of a different format for more range of output values.</p>
</li>
</ul>
<p>In the example above src and dst are the same size. Let’s change it so we add every 2 values
from src to make dst. In other words, given <code class="notranslate" translate="no">[1, 2, 3, 4, 5, 6]</code> as input we want
<code class="notranslate" translate="no">[3, 7, 11]</code> as output. And further, let’s keep the source as 3x2 data</p>
<p>The basic formula to get a value from a 2D array as though it was a 1D array is</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">y = floor(indexInto1DArray / widthOf2DArray);
x = indexInto1DArray % widthOf2Array;
</code></pre>
<p>Given that, our fragment shader needs to change to this to add every 2 values.</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-glsl">#version 300 es
precision highp float;

uniform sampler2D srcTex;
uniform ivec2 dstDimensions;

out vec4 outColor;

vec4 getValueFrom2DTextureAs1DArray(sampler2D tex, ivec2 dimensions, int index) {
  int y = index / dimensions.x;
  int x = index % dimensions.x;
  return texelFetch(tex, ivec2(x, y), 0);
}

void main() {
  // compute a 1D index into dst
  ivec2 dstPixel = ivec2(gl_FragCoord.xy);
  int dstIndex = dstPixel.y * dstDimensions.x + dstPixel.x;

  ivec2 srcDimensions = textureSize(srcTex, 0);  // size of mip 0

  vec4 v1 = getValueFrom2DTextureAs1DArray(srcTex, srcDimensions, dstIndex * 2);
  vec4 v2 = getValueFrom2DTextureAs1DArray(srcTex, srcDimensions, dstIndex * 2 + 1);

  outColor = v1 + v2;
}
</code></pre>
<p>The function <code class="notranslate" translate="no">getValueFrom2DTextureAs1DArray</code> is basically our array accessor
function. That means these 2 lines</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-glsl">  vec4 v1 = getValueFrom2DTextureAs1DArray(srcTex, srcDimensions, dstIndex * 2.0);
  vec4 v2 = getValueFrom2DTextureAs1DArray(srcTex, srcDimensions, dstIndex * 2.0 + 1.0);
</code></pre>
<p>Effectively mean this</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-glsl">  vec4 v1 = srcTexAs1DArray[dstIndex * 2.0];
  vec4 v2 = setTexAs1DArray[dstIndex * 2.0 + 1.0];
</code></pre>
<p>In our JavaScript we need to lookup the location of <code class="notranslate" translate="no">dstDimensions</code></p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">const program = webglUtils.createProgramFromSources(gl, [vs, fs]);
const positionLoc = gl.getAttribLocation(program, 'position');
const srcTexLoc = gl.getUniformLocation(program, 'srcTex');
+const dstDimensionsLoc = gl.getUniformLocation(program, 'dstDimensions');
</code></pre>
<p>and set it</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">gl.useProgram(program);
gl.uniform1i(srcTexLoc, 0);  // tell the shader the src texture is on texture unit 0
+gl.uniform2f(dstDimensionsLoc, dstWidth, dstHeight);
</code></pre>
<p>and we need to change the size of the destination (the canvas)</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">const dstWidth = 3;
-const dstHeight = 2;
+const dstHeight = 1;
</code></pre>
<p>and with that we have now have the result array able to do math
with random access into the source array</p>
<p><div class="webgl_example_container">
  <iframe class="webgl_example" style=" " src="/webgl/resources/editor.html?url=/webgl/lessons/..%2Fwebgl-gpgpu-add-2-elements.html"></iframe>
  <a class="webgl_center" href="/webgl/lessons/../webgl-gpgpu-add-2-elements.html" target="_blank">click here to open in a separate window</a>
</div>

</p>
<p>If you wanted to use more arrays as input just add more textures to put more
data in the same texture.</p>
<h2 id="now-lets-do-it-with-transform-feedback">Now let’s do it with <em>transform feedback</em></h2>
<p>“Transform Feedback” is a fancy name for the ability to write the output
of varyings in a vertex shader to one or more buffers.</p>
<p>The advantage to using transform feedback is the output is 1D
so it’s probably easier to reason about. It’s even closer to <code class="notranslate" translate="no">map</code> from JavaScript.</p>
<p>Let’s take in 2 arrays of values and output their sum, their difference,
and their product. Here’s the vertex shader</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-glsl">#version 300 es

in float a;
in float b;

out float sum;
out float difference;
out float product;

void main() {
  sum = a + b;
  difference = a - b;
  product = a * b;
}
</code></pre>
<p>and the fragment shader is just enough to compile</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-glsl">#version 300 es
precision highp float;
void main() {
}
</code></pre>
<p>To use transform feedback we have to tell WebGL which varyings we want written
and in what order. We do that by calling <code class="notranslate" translate="no">gl.transformFeedbackVaryings</code> before
linking the shader program. Because of this we are not going to use our helper
to compile the shaders and link the program this time, just to make it clear
what we have to do.</p>
<p>So, here is the code for compiling a shader similar to the code in the very
<a href="webgl-fundamentals.html">first article</a>.</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">function createShader(gl, type, src) {
  const shader = gl.createShader(type);
  gl.shaderSource(shader, src);
  gl.compileShader(shader);
  if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
    throw new Error(gl.getShaderInfoLog(shader));
  }
  return shader;
}
</code></pre>
<p>We’ll use it to compile our 2 shaders and then attach them and call
<code class="notranslate" translate="no">gl.transformFeedbackVaryings</code> before linking</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">const vShader = createShader(gl, gl.VERTEX_SHADER, vs);
const fShader = createShader(gl, gl.FRAGMENT_SHADER, fs);

const program = gl.createProgram();
gl.attachShader(program, vShader);
gl.attachShader(program, fShader);
gl.transformFeedbackVaryings(
    program,
    ['sum', 'difference', 'product'],
    gl.SEPARATE_ATTRIBS,
);
gl.linkProgram(program);
if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
  throw new Error(gl.getProgramParameter(program));
}
</code></pre>
<p><code class="notranslate" translate="no">gl.transformFeedbackVaryings</code> takes 3 arguments. The program, an array of the names
of the varyings we want to write in the order you want them written.
If you did have a fragment shader that actually did
something then maybe some of your varyings are only for the fragment shader and so
don’t need to be written. In our case we will write all of our varyings so we pass
in the names of all 3. The last parameter can be 1 of 2 values. Either <code class="notranslate" translate="no">SEPARATE_ATTRIBS</code>
or <code class="notranslate" translate="no">INTERLEAVED_ATTRIBS</code>.</p>
<p><code class="notranslate" translate="no">SEPARATE_ATTRIBS</code> means each varying will be written to a different buffer.
<code class="notranslate" translate="no">INTERLEAVED_ATTRIBS</code> means all the varyings will be written to the same buffer
but interleaved on the order we specified. In our case since we specified
<code class="notranslate" translate="no">['sum', 'difference', 'product']</code> if we used <code class="notranslate" translate="no">INTERLEAVED_ATTRIBS</code> the output
would be <code class="notranslate" translate="no">sum0, difference0, product0, sum1, difference1, product1, sum2, difference2, product2, etc...</code>
into a single buffer. We’re using <code class="notranslate" translate="no">SEPARATE_ATTRIBS</code> though so instead
each output will be written to the a different buffer.</p>
<p>So, like other examples we need to setup buffers for our input attributes</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">const aLoc = gl.getAttribLocation(program, 'a');
const bLoc = gl.getAttribLocation(program, 'b');

// Create a vertex array object (attribute state)
const vao = gl.createVertexArray();
gl.bindVertexArray(vao);

function makeBuffer(gl, sizeOrData) {
  const buf = gl.createBuffer();
  gl.bindBuffer(gl.ARRAY_BUFFER, buf);
  gl.bufferData(gl.ARRAY_BUFFER, sizeOrData, gl.STATIC_DRAW);
  return buf;
}

function makeBufferAndSetAttribute(gl, data, loc) {
  const buf = makeBuffer(gl, data);
  // setup our attributes to tell WebGL how to pull
  // the data from the buffer above to the attribute
  gl.enableVertexAttribArray(loc);
  gl.vertexAttribPointer(
      loc,
      1,         // size (num components)
      gl.FLOAT,  // type of data in buffer
      false,     // normalize
      0,         // stride (0 = auto)
      0,         // offset
  );
}

const a = [1, 2, 3, 4, 5, 6];
const b = [3, 6, 9, 12, 15, 18];

// put data in buffers
const aBuffer = makeBufferAndSetAttribute(gl, new Float32Array(a), aLoc);
const bBuffer = makeBufferAndSetAttribute(gl, new Float32Array(b), bLoc);
</code></pre>
<p>Then we need to setup a “transform feedback”. A “transform feedback” is an object
that contains the state of the buffers we will write to. Whereas an <a href="webgl-attributes.html">vertex array</a>
specifies the state of all the input attributes, a “transform feedback” contains the
state of all the output attributes.</p>
<p>Here is the code to set ours up</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">// Create and fill out a transform feedback
const tf = gl.createTransformFeedback();
gl.bindTransformFeedback(gl.TRANSFORM_FEEDBACK, tf);

// make buffers for output
const sumBuffer = makeBuffer(gl, a.length * 4);
const differenceBuffer = makeBuffer(gl, a.length * 4);
const productBuffer = makeBuffer(gl, a.length * 4);

// bind the buffers to the transform feedback
gl.bindBufferBase(gl.TRANSFORM_FEEDBACK_BUFFER, 0, sumBuffer);
gl.bindBufferBase(gl.TRANSFORM_FEEDBACK_BUFFER, 1, differenceBuffer);
gl.bindBufferBase(gl.TRANSFORM_FEEDBACK_BUFFER, 2, productBuffer);

gl.bindTransformFeedback(gl.TRANSFORM_FEEDBACK, null);

// buffer's we are writing to can not be bound else where
gl.bindBuffer(gl.ARRAY_BUFFER, null);  // productBuffer was still bound to ARRAY_BUFFER so unbind it
</code></pre>
<p>We call <code class="notranslate" translate="no">bindBufferBase</code> to set which buffer, each of the outputs, output 0, output 1, and output 2
will write to. Outputs 0, 1, 2 correspond to the names we passed to <code class="notranslate" translate="no">gl.transformFeedbackVaryings</code>
when we linked the program.</p>
<p>When we’re done the “transform feedback” we created has state like this</p>
<img src="resources/transform-feedback-diagram.png" style="width: 625px;" class="webgl_center">
<p>There is also a function <code class="notranslate" translate="no">bindBufferRange</code> that lets us specify a sub range within a buffer where
we will write to but we won’t use that here.</p>
<p>So to execute the shader we do this</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">gl.useProgram(program);

// bind our input attribute state for the a and b buffers
gl.bindVertexArray(vao);

// no need to call the fragment shader
gl.enable(gl.RASTERIZER_DISCARD);

gl.bindTransformFeedback(gl.TRANSFORM_FEEDBACK, tf);
gl.beginTransformFeedback(gl.POINTS);
gl.drawArrays(gl.POINTS, 0, a.length);
gl.endTransformFeedback();
gl.bindTransformFeedback(gl.TRANSFORM_FEEDBACK, null);

// turn on using fragment shaders again
gl.disable(gl.RASTERIZER_DISCARD);
</code></pre>
<p>We turn off calling the fragment shader. We bind the transform feedback object
we created earlier, we turn on transform feedback, then we call draw.</p>
<p>To look at the values we can call <code class="notranslate" translate="no">gl.getBufferSubData</code></p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">log(`a: ${a}`);
log(`b: ${b}`);

printResults(gl, sumBuffer, 'sums');
printResults(gl, differenceBuffer, 'differences');
printResults(gl, productBuffer, 'products');

function printResults(gl, buffer, label) {
  const results = new Float32Array(a.length);
  gl.bindBuffer(gl.ARRAY_BUFFER, buffer);
  gl.getBufferSubData(
      gl.ARRAY_BUFFER,
      0,    // byte offset into GPU buffer,
      results,
  );
  // print the results
  log(`${label}: ${results}`);
}
</code></pre>
<p><div class="webgl_example_container">
  <iframe class="webgl_example" style=" " src="/webgl/resources/editor.html?url=/webgl/lessons/..%2Fwebgl-gpgpu-sum-difference-product-transformfeedback.html"></iframe>
  <a class="webgl_center" href="/webgl/lessons/../webgl-gpgpu-sum-difference-product-transformfeedback.html" target="_blank">click here to open in a separate window</a>
</div>

</p>
<p>You can see it worked. We got the GPU to compute the sum, difference, and product
of the ‘a’ and ‘b’ values we passed in.</p>
<p>Note: You might find <a href="https://webgl2fundamentals.org/webgl/lessons/resources/webgl-state-diagram.html?exampleId=transform-feedback">this state diagram transform feedback example</a> helpful in visualizing what a “transform feedback”
is. It’s not the same example as above though. The vertex shader it uses with transform feedback generates positions and colors for a circle of points.</p>
<h2 id="first-example-particles">First example: particles</h2>
<p>Let’s say you have a very simple particle system.
Every particle just has a position and a velocity and
if it goes off one edge of the screen it wraps around to
the other side.</p>
<p>Given most of the other articles on this site you’d
update the positions of the particles in JavaScript</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">for (const particle of particles) {
  particle.pos.x = (particle.pos.x + particle.velocity.x) % canvas.width;
  particle.pos.y = (particle.pos.y + particle.velocity.y) % canvas.height;
}
</code></pre>
<p>and then draw the particles either one at a time</p>
<pre class="prettyprint notranslate" translate="no"><code class="notranslate" translate="no">useProgram (particleShader)
setup particle attributes
for each particle
  set uniforms
  draw particle
</code></pre>
<p>Or you might upload all the new particle positions</p>
<pre class="prettyprint notranslate" translate="no"><code class="notranslate" translate="no">bindBuffer(..., particlePositionBuffer)
bufferData(..., latestParticlePositions, ...)
useProgram (particleShader)
setup particle attributes
set uniforms
draw particles
</code></pre>
<p>Using the transform feedback example above we could make
a buffer with the velocity for each particle. Then we could
make 2 buffers for the positions. We’d use transform feedback
to add the velocity to one position buffer and write it to the
other position buffer. Then we’d draw with the new positions.
On the next frame we’d read from the buffer with the new positions
and write back to the other buffer to generate newer positions.</p>
<p>Here’s the vertex shader to update the particle positions</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-glsl">#version 300 es
in vec2 oldPosition;
in vec2 velocity;

uniform float deltaTime;
uniform vec2 canvasDimensions;

out vec2 newPosition;

vec2 euclideanModulo(vec2 n, vec2 m) {
	return mod(mod(n, m) + m, m);
}

void main() {
  newPosition = euclideanModulo(
      oldPosition + velocity * deltaTime,
      canvasDimensions);
}
</code></pre>
<p>To draw the particles we’ll just use a simple vertex shader</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-glsl">#version 300 es
in vec4 position;
uniform mat4 matrix;

void main() {
  // do the common matrix math
  gl_Position = matrix * position;
  gl_PointSize = 10.0;
}
</code></pre>
<p>Let’s turn the code for creating and linking a program into
a function we can use for both shaders</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">function createProgram(gl, shaderSources, transformFeedbackVaryings) {
  const program = gl.createProgram();
  [gl.VERTEX_SHADER, gl.FRAGMENT_SHADER].forEach((type, ndx) =&gt; {
    const shader = createShader(gl, type, shaderSources[ndx]);
    gl.attachShader(program, shader);
  });
  if (transformFeedbackVaryings) {
    gl.transformFeedbackVaryings(
        program,
        transformFeedbackVaryings,
        gl.SEPARATE_ATTRIBS,
    );
  }
  gl.linkProgram(program);
  if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
    throw new Error(gl.getProgramParameter(program));
  }
  return program;
}
</code></pre>
<p>and then use it to compile the shaders, one with a transform feedback
varying.</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">const updatePositionProgram = createProgram(
    gl, [updatePositionVS, updatePositionFS], ['newPosition']);
const drawParticlesProgram = createProgram(
    gl, [drawParticlesVS, drawParticlesFS]);
</code></pre>
<p>As usual we need to lookup locations</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">const updatePositionPrgLocs = {
  oldPosition: gl.getAttribLocation(updatePositionProgram, 'oldPosition'),
  velocity: gl.getAttribLocation(updatePositionProgram, 'velocity'),
  canvasDimensions: gl.getUniformLocation(updatePositionProgram, 'canvasDimensions'),
  deltaTime: gl.getUniformLocation(updatePositionProgram, 'deltaTime'),
};

const drawParticlesProgLocs = {
  position: gl.getAttribLocation(drawParticlesProgram, 'position'),
  matrix: gl.getUniformLocation(drawParticlesProgram, 'matrix'),
};
</code></pre>
<p>Now let’s make some random positions and velocities</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">// create random positions and velocities.
const rand = (min, max) =&gt; {
  if (max === undefined) {
    max = min;
    min = 0;
  }
  return Math.random() * (max - min) + min;
};
const numParticles = 200;
const createPoints = (num, ranges) =&gt;
   new Array(num).fill(0).map(_ =&gt; ranges.map(range =&gt; rand(...range))).flat();
const positions = new Float32Array(createPoints(numParticles, [[canvas.width], [canvas.height]]));
const velocities = new Float32Array(createPoints(numParticles, [[-300, 300], [-300, 300]]));
</code></pre>
<p>Then we’ll put those into buffers.</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">function makeBuffer(gl, sizeOrData, usage) {
  const buf = gl.createBuffer();
  gl.bindBuffer(gl.ARRAY_BUFFER, buf);
  gl.bufferData(gl.ARRAY_BUFFER, sizeOrData, usage);
  return buf;
}

const position1Buffer = makeBuffer(gl, positions, gl.DYNAMIC_DRAW);
const position2Buffer = makeBuffer(gl, positions, gl.DYNAMIC_DRAW);
const velocityBuffer = makeBuffer(gl, velocities, gl.STATIC_DRAW);
</code></pre>
<p>Note that we passed in <code class="notranslate" translate="no">gl.DYNAMIC_DRAW</code> to <code class="notranslate" translate="no">gl.bufferData</code> for the 2 position buffers
since we’ll be updating them often. This is just a hint to WebGL for optimization.
Whether it has any effect on performance is up to WebGL.</p>
<p>We need 4 vertex arrays.</p>
<ul>
<li>1 for using <code class="notranslate" translate="no">position1Buffer</code> and <code class="notranslate" translate="no">velocity</code> when updating positions</li>
<li>1 for using <code class="notranslate" translate="no">position2Buffer</code> and <code class="notranslate" translate="no">velocity</code> when updating positions</li>
<li>1 for using <code class="notranslate" translate="no">position1Buffer</code> when drawing</li>
<li>1 for using <code class="notranslate" translate="no">position2Buffer</code> when drawing</li>
</ul>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">function makeVertexArray(gl, bufLocPairs) {
  const va = gl.createVertexArray();
  gl.bindVertexArray(va);
  for (const [buffer, loc] of bufLocPairs) {
    gl.bindBuffer(gl.ARRAY_BUFFER, buffer);
    gl.enableVertexAttribArray(loc);
    gl.vertexAttribPointer(
        loc,      // attribute location
        2,        // number of elements
        gl.FLOAT, // type of data
        false,    // normalize
        0,        // stride (0 = auto)
        0,        // offset
    );
  }
  return va;
}

const updatePositionVA1 = makeVertexArray(gl, [
  [position1Buffer, updatePositionPrgLocs.oldPosition],
  [velocityBuffer, updatePositionPrgLocs.velocity],
]);
const updatePositionVA2 = makeVertexArray(gl, [
  [position2Buffer, updatePositionPrgLocs.oldPosition],
  [velocityBuffer, updatePositionPrgLocs.velocity],
]);

const drawVA1 = makeVertexArray(
    gl, [[position1Buffer, drawParticlesProgLocs.position]]);
const drawVA2 = makeVertexArray(
    gl, [[position2Buffer, drawParticlesProgLocs.position]]);
</code></pre>
<p>We then make 2 transform feedback objects.</p>
<ul>
<li>1 for writing to <code class="notranslate" translate="no">position1Buffer</code></li>
<li>1 for writing to <code class="notranslate" translate="no">position2Buffer</code></li>
</ul>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">function makeTransformFeedback(gl, buffer) {
  const tf = gl.createTransformFeedback();
  gl.bindTransformFeedback(gl.TRANSFORM_FEEDBACK, tf);
  gl.bindBufferBase(gl.TRANSFORM_FEEDBACK_BUFFER, 0, buffer);
  return tf;
}

const tf1 = makeTransformFeedback(gl, position1Buffer);
const tf2 = makeTransformFeedback(gl, position2Buffer);
</code></pre>
<p>When using transform feedback it’s important to unbind buffers
from other bind points. <code class="notranslate" translate="no">ARRAY_BUFFER</code> still has the last buffer
bound that we put data in. <code class="notranslate" translate="no">TRANSFORM_FEEDBACK_BUFFER</code> is set when
calling <code class="notranslate" translate="no">gl.bindBufferBase</code>. That is a little confusing. Calling
<code class="notranslate" translate="no">gl.bindBufferBase</code> with <code class="notranslate" translate="no">TRANSFORM_FEEDBACK_BUFFER</code> actually
binds the buffer to 2 places. One, to indexed bind point inside
the transform feedback object. The other is to a kind of global
bind point called <code class="notranslate" translate="no">TRANSFORM_FEEDBACK_BUFFER</code>.</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">// unbind left over stuff
gl.bindBuffer(gl.ARRAY_BUFFER, null);
gl.bindBuffer(gl.TRANSFORM_FEEDBACK_BUFFER, null);
</code></pre>
<p>So that we can easily swap updating and drawing buffers
we’ll setup these 2 objects</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">let current = {
  updateVA: updatePositionVA1,  // read from position1
  tf: tf2,                      // write to position2
  drawVA: drawVA2,              // draw with position2
};
let next = {
  updateVA: updatePositionVA2,  // read from position2
  tf: tf1,                      // write to position1
  drawVA: drawVA1,              // draw with position1
};
</code></pre>
<p>Then we’ll do a render loop, first we’ll update the positions
using transform feedback.</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">let then = 0;
function render(time) {
  // convert to seconds
  time *= 0.001;
  // Subtract the previous time from the current time
  const deltaTime = time - then;
  // Remember the current time for the next frame.
  then = time;

  webglUtils.resizeCanvasToDisplaySize(gl.canvas);

  gl.clear(gl.COLOR_BUFFER_BIT);

  // compute the new positions
  gl.useProgram(updatePositionProgram);
  gl.bindVertexArray(current.updateVA);
  gl.uniform2f(updatePositionPrgLocs.canvasDimensions, gl.canvas.width, gl.canvas.height);
  gl.uniform1f(updatePositionPrgLocs.deltaTime, deltaTime);

  // turn of using the fragment shader
  gl.enable(gl.RASTERIZER_DISCARD);

  gl.bindTransformFeedback(gl.TRANSFORM_FEEDBACK, current.tf);
  gl.beginTransformFeedback(gl.POINTS);
  gl.drawArrays(gl.POINTS, 0, numParticles);
  gl.endTransformFeedback();
  gl.bindTransformFeedback(gl.TRANSFORM_FEEDBACK, null);

  // turn on using fragment shaders again
  gl.disable(gl.RASTERIZER_DISCARD);
</code></pre>
<p>and then draw the particles</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">  // now draw the particles.
  gl.useProgram(drawParticlesProgram);
  gl.bindVertexArray(current.drawVA);
  gl.viewport(0, 0, gl.canvas.width, gl.canvas.height);
  gl.uniformMatrix4fv(
      drawParticlesProgLocs.matrix,
      false,
      m4.orthographic(0, gl.canvas.width, 0, gl.canvas.height, -1, 1));
  gl.drawArrays(gl.POINTS, 0, numParticles);
</code></pre>
<p>and finally swap <code class="notranslate" translate="no">current</code> and <code class="notranslate" translate="no">next</code> so that next frame we’ll
use the latest positions to generate new ones</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">  // swap which buffer we will read from
  // and which one we will write to
  {
    const temp = current;
    current = next;
    next = temp;
  }

  requestAnimationFrame(render);
}
requestAnimationFrame(render);
</code></pre>
<p>And with that we have simple GPU based particles.</p>
<p><div class="webgl_example_container">
  <iframe class="webgl_example" style=" " src="/webgl/resources/editor.html?url=/webgl/lessons/..%2Fwebgl-gpgpu-particles-transformfeedback.html"></iframe>
  <a class="webgl_center" href="/webgl/lessons/../webgl-gpgpu-particles-transformfeedback.html" target="_blank">click here to open in a separate window</a>
</div>

</p>
<h2 id="next-example-finding-the-closest-line-segment-to-a-point">Next Example: Finding the closest line segment to a point</h2>
<p>I’m not sure this is a good example but it’s the one I wrote. I say it might
not be good because I suspect there are better algorithms for finding
the closest line to a point than brute force checking every line with the point. For example various space partitioning algorithms might let you easily discard 95%
of the points and so be faster. Still, this example probably does show
some techniques of GPGPU at least.</p>
<p>The problem: We have 500 points and 1000 line segments. For each point
find which line segment it is closest to. The brute force method is</p>
<pre class="prettyprint notranslate" translate="no"><code class="notranslate" translate="no">for each point
  minDistanceSoFar = MAX_VALUE
  for each line segment
    compute distance from point to line segment
    if distance is &lt; minDistanceSoFar
       minDistanceSoFar = distance
       closestLine = line segment
</code></pre>
<p>For 500 points each checking 1000 lines that’s 500,000 checks.
Modern GPUs have 100s or 1000s of cores so if we could do this on
the GPU we could potentially run hundreds or thousands of times faster.</p>
<p>This time, while we can put the points in a buffer like we did for the particles
we can’t put the line segments in a buffer. Buffers supply their data via
attributes. That means we can’t randomly access any value on demand, instead
the values are assigned to the attribute outside the shader’s control.</p>
<p>So, we need to put the line positions in a texture, which as we pointed out
above is another word for a 2D array though we can still treat that 2D
array as a 1D array if we want.</p>
<p>Here’s the vertex shader that finds the closest line for a single point.
It’s exactly the brute force algorithm as above</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">  const closestLineVS = `#version 300 es
  in vec3 point;

  uniform sampler2D linesTex;
  uniform int numLineSegments;

  flat out int closestNdx;

  vec4 getAs1D(sampler2D tex, ivec2 dimensions, int index) {
    int y = index / dimensions.x;
    int x = index % dimensions.x;
    return texelFetch(tex, ivec2(x, y), 0);
  }

  // from https://stackoverflow.com/a/6853926/128511
  // a is the point, b,c is the line segment
  float distanceFromPointToLine(in vec3 a, in vec3 b, in vec3 c) {
    vec3 ba = a - b;
    vec3 bc = c - b;
    float d = dot(ba, bc);
    float len = length(bc);
    float param = 0.0;
    if (len != 0.0) {
      param = clamp(d / (len * len), 0.0, 1.0);
    }
    vec3 r = b + bc * param;
    return distance(a, r);
  }

  void main() {
    ivec2 linesTexDimensions = textureSize(linesTex, 0);
    
    // find the closest line segment
    float minDist = 10000000.0; 
    int minIndex = -1;
    for (int i = 0; i &lt; numLineSegments; ++i) {
      vec3 lineStart = getAs1D(linesTex, linesTexDimensions, i * 2).xyz;
      vec3 lineEnd = getAs1D(linesTex, linesTexDimensions, i * 2 + 1).xyz;
      float dist = distanceFromPointToLine(point, lineStart, lineEnd);
      if (dist &lt; minDist) {
        minDist = dist;
        minIndex = i;
      }
    }
    
    closestNdx = minIndex;
  }
  `;
</code></pre>
<p>I renamed <code class="notranslate" translate="no">getValueFrom2DTextureAs1DArray</code> to <code class="notranslate" translate="no">getAs1D</code> just to make
some of the lines shorter and more readable.
Otherwise it’s a pretty straight forward implementation of the brute force algorithm
we wrote above.</p>
<p><code class="notranslate" translate="no">point</code> is the current point. <code class="notranslate" translate="no">linesTex</code> contains the points for the
line segment in pairs, first point, followed by second point.</p>
<p>First let’s make some test data. Here’s 2 points and 5 lines. They are
padded with 0, 0 because each one will stored in an RGBA texture.</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">const points = [
  100, 100,
  200, 100,
];
const lines = [
   25,  50,
   25, 150,
   90,  50,
   90, 150,
  125,  50,
  125, 150,
  185,  50,
  185, 150,
  225,  50,
  225, 150,
];
const numPoints = points.length / 2;
const numLineSegments = lines.length / 2 / 2;
</code></pre>
<p>If we plot those out they look like this</p>
<img src="resources/line-segments-points.svg" style="width: 500px;" class="webgl_center">
<p>The lines are numbered 0 to 4 from left to right,
so if our code works the first point (<span style="color: red;">red</span>)
should get a value of 1 as the closest line, the second point
(<span style="color: green;">green</span>), should get a value of 3.</p>
<p>Lets put the points in a buffer as well as make a buffer to hold the computed
closest index for each</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">const closestNdxBuffer = makeBuffer(gl, points.length * 4, gl.STATIC_DRAW);
const pointsBuffer = makeBuffer(gl, new Float32Array(points), gl.DYNAMIC_DRAW);
</code></pre>
<p>and lets make a texture to hold all the end points of the lines.</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">function createDataTexture(gl, data, numComponents, internalFormat, format, type) {
  const numElements = data.length / numComponents;

  // compute a size that will hold all of our data
  const width = Math.ceil(Math.sqrt(numElements));
  const height = Math.ceil(numElements / width);

  const bin = new Float32Array(width * height * numComponents);
  bin.set(data);

  const tex = gl.createTexture();
  gl.bindTexture(gl.TEXTURE_2D, tex);
  gl.texImage2D(
      gl.TEXTURE_2D,
      0,        // mip level
      internalFormat,
      width,
      height,
      0,        // border
      format,
      type,
      bin,
  );
  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST);
  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.NEAREST);
  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
  return {tex, dimensions: [width, height]};
}

const {tex: linesTex, dimensions: linesTexDimensions} =
    createDataTexture(gl, lines, 2, gl.RG32F, gl.RG, gl.FLOAT);
</code></pre>
<p>In this case we’re letting the code choose the dimensions of the texture
and letting it pad the texture out. For example if we gave it an array
with 7 entries it would stick that in a 3x3 texture. It returns
both the texture and the dimensions it chose. Why do we let it choose
the dimension? Because textures have a maximum dimension.</p>
<p>Ideally we’d just like to look at our data as a 1 dimensional array
of positions, 1 dimensional array of line points etc. So we could just
declare a texture to be Nx1. Unfortunately GPUs have a maximum
dimension and that can be as low as 1024 or 2048. If the limit
was 1024 and we needed 1025 values in our array we’d have to put the data
in a texture like say 512x2. By putting the data in a square we won’t
hit the limit until we hit the maximum texture dimension squared.
For a dimension limit of 1024 that would allow arrays of over 1 million values.</p>
<p>Next up compile the shader and look up the locations</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">const closestLinePrg = createProgram(
    gl, [closestLineVS, closestLineFS], ['closestNdx']);

const closestLinePrgLocs = {
  point: gl.getAttribLocation(closestLinePrg, 'point'),
  linesTex: gl.getUniformLocation(closestLinePrg, 'linesTex'),
  numLineSegments: gl.getUniformLocation(closestLinePrg, 'numLineSegments'),
};
</code></pre>
<p>And make a vertex array for the points</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">function makeVertexArray(gl, bufLocPairs) {
  const va = gl.createVertexArray();
  gl.bindVertexArray(va);
  for (const [buffer, loc] of bufLocPairs) {
    gl.bindBuffer(gl.ARRAY_BUFFER, buffer);
    gl.enableVertexAttribArray(loc);
    gl.vertexAttribPointer(
        loc,      // attribute location
        2,        // number of elements
        gl.FLOAT, // type of data
        false,    // normalize
        0,        // stride (0 = auto)
        0,        // offset
    );
  }
  return va;
}

const closestLinesVA = makeVertexArray(gl, [
  [pointsBuffer, closestLinePrgLocs.point],
]);
</code></pre>
<p>Now we need to setup a transform feedback to let us write the results to the
<code class="notranslate" translate="no">cloestNdxBuffer</code>.</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">function makeTransformFeedback(gl, buffer) {
  const tf = gl.createTransformFeedback();
  gl.bindTransformFeedback(gl.TRANSFORM_FEEDBACK, tf);
  gl.bindBufferBase(gl.TRANSFORM_FEEDBACK_BUFFER, 0, buffer);
  return tf;
}

const closestNdxTF = makeTransformFeedback(gl, closestNdxBuffer);
</code></pre>
<p>With all of that setup we can render</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">// compute the closest lines
gl.bindVertexArray(closestLinesVA);
gl.useProgram(closestLinePrg);
gl.uniform1i(closestLinePrgLocs.linesTex, 0);
gl.uniform1i(closestLinePrgLocs.numLineSegments, numLineSegments);

// turn of using the fragment shader
gl.enable(gl.RASTERIZER_DISCARD);

gl.bindTransformFeedback(gl.TRANSFORM_FEEDBACK, closestNdxTF);
gl.beginTransformFeedback(gl.POINTS);
gl.drawArrays(gl.POINTS, 0, numPoints);
gl.endTransformFeedback();
gl.bindTransformFeedback(gl.TRANSFORM_FEEDBACK, null);

// turn on using fragment shaders again
gl.disable(gl.RASTERIZER_DISCARD);
</code></pre>
<p>and finally read the result</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">// get the results.
{
  const results = new Int32Array(numPoints);
  gl.bindBuffer(gl.ARRAY_BUFFER, closestNdxBuffer);
  gl.getBufferSubData(gl.ARRAY_BUFFER, 0, results);
  log(results);
}
</code></pre>
<p>If we run it</p>
<p><div class="webgl_example_container">
  <iframe class="webgl_example" style=" " src="/webgl/resources/editor.html?url=/webgl/lessons/..%2Fwebgl-gpgpu-closest-line-results-transformfeedback.html"></iframe>
  <a class="webgl_center" href="/webgl/lessons/../webgl-gpgpu-closest-line-results-transformfeedback.html" target="_blank">click here to open in a separate window</a>
</div>

</p>
<p>We should get the expected result of <code class="notranslate" translate="no">[1, 3]</code></p>
<p>Reading data back from the GPU is slow. Let’s say we wanted to
visualize the results. It would be pretty easy to read those results
back to JavaScript and draw them but how about without reading them
back to JavaScript? Let’s use the data as is and draw the results?</p>
<p>First, drawing the points is relatively easy. It’s the same as the particle example
Let’s draw each point in a different color so we can highlight the closest line in the same color.</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">const drawPointsVS = `#version 300 es
in vec4 point;

uniform float numPoints;
uniform mat4 matrix;

out vec4 v_color;

// converts hue, saturation, and value each in the 0 to 1 range
// to rgb.  c = color, c.x = hue, c.y = saturation, c.z = value
vec3 hsv2rgb(vec3 c) {
  c = vec3(c.x, clamp(c.yz, 0.0, 1.0));
  vec4 K = vec4(1.0, 2.0 / 3.0, 1.0 / 3.0, 3.0);
  vec3 p = abs(fract(c.xxx + K.xyz) * 6.0 - K.www);
  return c.z * mix(K.xxx, clamp(p - K.xxx, 0.0, 1.0), c.y);
}

void main() {
  gl_Position = matrix * point;
  gl_PointSize = 10.0;

  float hue = float(gl_VertexID) / numPoints;
  v_color = vec4(hsv2rgb(vec3(hue, 1, 1)), 1);
}
`;

const drawClosestLinesPointsFS = `#version 300 es
precision highp float;
in vec4 v_color;
out vec4 outColor;
void main() {
  outColor = v_color;
}`;
</code></pre>
<p>Rather than passing in colors we generate them using <code class="notranslate" translate="no">hsv2rgb</code> and passing it
a hue from to 0 to 1. For 500 points there would
be no easy way to tell lines apart but for around 10 points we should be
able to distinguish them.</p>
<p>We pass the generated color to a simple fragment shader</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">const drawClosestPointsLinesFS = `
precision highp float;
varying vec4 v_color;
void main() {
  gl_FragColor = v_color;
}
`;
</code></pre>
<p>To draw all the lines, even the ones that are not close to any points is
almost the same except we don’t generate a color. In this case we’re just
using a hardcoded color.</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">const drawLinesVS = `#version 300 es
uniform sampler2D linesTex;
uniform mat4 matrix;

out vec4 v_color;

vec4 getAs1D(sampler2D tex, ivec2 dimensions, int index) {
  int y = index / dimensions.x;
  int x = index % dimensions.x;
  return texelFetch(tex, ivec2(x, y), 0);
}

void main() {
  ivec2 linesTexDimensions = textureSize(linesTex, 0);

  // pull the position from the texture
  vec4 position = getAs1D(linesTex, linesTexDimensions, gl_VertexID);

  // do the common matrix math
  gl_Position = matrix * vec4(position.xy, 0, 1);

  // just so we can use the same fragment shader
  v_color = vec4(0.8, 0.8, 0.8, 1);
}
`;
</code></pre>
<p>We don’t have any attributes. We just use <code class="notranslate" translate="no">gl_VertexID</code> like we covered in
<a href="webgl-drawing-without-data.html">the article on drawing without data</a>.</p>
<p>Finally drawing closest lines works like this</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">const drawClosestLinesVS = `#version 300 es
in int closestNdx;
uniform float numPoints;
uniform sampler2D linesTex;
uniform mat4 matrix;

out vec4 v_color;

vec4 getAs1D(sampler2D tex, ivec2 dimensions, int index) {
  int y = index / dimensions.x;
  int x = index % dimensions.x;
  return texelFetch(tex, ivec2(x, y), 0);
}

// converts hue, saturation, and value each in the 0 to 1 range
// to rgb.  c = color, c.x = hue, c.y = saturation, c.z = value
vec3 hsv2rgb(vec3 c) {
  c = vec3(c.x, clamp(c.yz, 0.0, 1.0));
  vec4 K = vec4(1.0, 2.0 / 3.0, 1.0 / 3.0, 3.0);
  vec3 p = abs(fract(c.xxx + K.xyz) * 6.0 - K.www);
  return c.z * mix(K.xxx, clamp(p - K.xxx, 0.0, 1.0), c.y);
}

void main() {
  ivec2 linesTexDimensions = textureSize(linesTex, 0);

  // pull the position from the texture
  int linePointId = closestNdx * 2 + gl_VertexID % 2;
  vec4 position = getAs1D(linesTex, linesTexDimensions, linePointId);

  // do the common matrix math
  gl_Position = matrix * vec4(position.xy, 0, 1);

  int pointId = gl_InstanceID;
  float hue = float(pointId) / numPoints;
  v_color = vec4(hsv2rgb(vec3(hue, 1, 1)), 1);
}
`;
</code></pre>
<p>We pass in <code class="notranslate" translate="no">closestNdx</code> as an attribute. These are the results we generated.
Using that we can look up specific line. We need to draw 2 points per line
though so we’ll use <a href="webgl-instanced-drawing.html">instanced drawing</a> to
draw 2 points per <code class="notranslate" translate="no">closestNdx</code>. We can then use <code class="notranslate" translate="no">gl_VertexID % 2</code> to choose
the starting or ending point.</p>
<p>Finally we compute a color using the same method we used when drawing points
so they’ll match their points.</p>
<p>We need to compile all of these new shader programs and look up locations</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">const closestLinePrg = createProgram(
    gl, [closestLineVS, closestLineFS], ['closestNdx']);
+const drawLinesPrg = createProgram(
+    gl, [drawLinesVS, drawClosestLinesPointsFS]);
+const drawClosestLinesPrg = createProgram(
+    gl, [drawClosestLinesVS, drawClosestLinesPointsFS]);
+const drawPointsPrg = createProgram(
+    gl, [drawPointsVS, drawClosestLinesPointsFS]);

const closestLinePrgLocs = {
  point: gl.getAttribLocation(closestLinePrg, 'point'),
  linesTex: gl.getUniformLocation(closestLinePrg, 'linesTex'),
  numLineSegments: gl.getUniformLocation(closestLinePrg, 'numLineSegments'),
};
+const drawLinesPrgLocs = {
+  linesTex: gl.getUniformLocation(drawLinesPrg, 'linesTex'),
+  matrix: gl.getUniformLocation(drawLinesPrg, 'matrix'),
+};
+const drawClosestLinesPrgLocs = {
+  closestNdx: gl.getAttribLocation(drawClosestLinesPrg, 'closestNdx'),
+  linesTex: gl.getUniformLocation(drawClosestLinesPrg, 'linesTex'),
+  matrix: gl.getUniformLocation(drawClosestLinesPrg, 'matrix'),
+  numPoints: gl.getUniformLocation(drawClosestLinesPrg, 'numPoints'),
+};
+const drawPointsPrgLocs = {
+  point: gl.getAttribLocation(drawPointsPrg, 'point'),
+  matrix: gl.getUniformLocation(drawPointsPrg, 'matrix'),
+  numPoints: gl.getUniformLocation(drawPointsPrg, 'numPoints'),
+};
</code></pre>
<p>We need to vertex arrays for drawing the points and the closest lines.</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">const closestLinesVA = makeVertexArray(gl, [
  [pointsBuffer, closestLinePrgLocs.point],
]);

+const drawClosestLinesVA = gl.createVertexArray();
+gl.bindVertexArray(drawClosestLinesVA);
+gl.bindBuffer(gl.ARRAY_BUFFER, closestNdxBuffer);
+gl.enableVertexAttribArray(drawClosestLinesPrgLocs.closestNdx);
+gl.vertexAttribIPointer(drawClosestLinesPrgLocs.closestNdx, 1, gl.INT, 0, 0);
+gl.vertexAttribDivisor(drawClosestLinesPrgLocs.closestNdx, 1);
+
+const drawPointsVA = makeVertexArray(gl, [
+  [pointsBuffer, drawPointsPrgLocs.point],
+]);
</code></pre>
<p>So, at render time we compute the results like we did before but
we don’t look up the results with <code class="notranslate" translate="no">getBufferSubData</code>. Instead we just
pass them to the appropriate shaders.</p>
<p>First we draw all the lines in gray</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">// draw all the lines in gray
gl.bindFramebuffer(gl.FRAMEBUFFER, null);
gl.viewport(0, 0, gl.canvas.width, gl.canvas.height);

gl.bindVertexArray(null);
gl.useProgram(drawLinesPrg);

// bind the lines texture to texture unit 0
gl.activeTexture(gl.TEXTURE0);
gl.bindTexture(gl.TEXTURE_2D, linesTex);

// Tell the shader to use texture on texture unit 0
gl.uniform1i(drawLinesPrgLocs.linesTex, 0);
gl.uniformMatrix4fv(drawLinesPrgLocs.matrix, false, matrix);

gl.drawArrays(gl.LINES, 0, numLineSegments * 2);
</code></pre>
<p>Then we draw all the closest lines</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">gl.bindVertexArray(drawClosestLinesVA);
gl.useProgram(drawClosestLinesPrg);

gl.activeTexture(gl.TEXTURE0);
gl.bindTexture(gl.TEXTURE_2D, linesTex);

gl.uniform1i(drawClosestLinesPrgLocs.linesTex, 0);
gl.uniform1f(drawClosestLinesPrgLocs.numPoints, numPoints);
gl.uniformMatrix4fv(drawClosestLinesPrgLocs.matrix, false, matrix);

gl.drawArraysInstanced(gl.LINES, 0, 2, numPoints);
</code></pre>
<p>and finally we draw each point</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">gl.bindVertexArray(drawPointsVA);
gl.useProgram(drawPointsPrg);

gl.uniform1f(drawPointsPrgLocs.numPoints, numPoints);
gl.uniformMatrix4fv(drawPointsPrgLocs.matrix, false, matrix);

gl.drawArrays(gl.POINTS, 0, numPoints);
</code></pre>
<p>Before we run it lets do one more thing. Let’s add more points and lines</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">-const points = [
-  100, 100,
-  200, 100,
-];
-const lines = [
-   25,  50,
-   25, 150,
-   90,  50,
-   90, 150,
-  125,  50,
-  125, 150,
-  185,  50,
-  185, 150,
-  225,  50,
-  225, 150,
-];

+function createPoints(numPoints, ranges) {
+  const points = [];
+  for (let i = 0; i &lt; numPoints; ++i) {
+    points.push(...ranges.map(range =&gt; r(...range)));
+  }
+  return points;
+}
+
+const r = (min, max) =&gt; min + Math.random() * (max - min);
+
+const points = createPoints(8, [[0, gl.canvas.width], [0, gl.canvas.height]]);
+const lines = createPoints(125 * 2, [[0, gl.canvas.width], [0, gl.canvas.height]]);
const numPoints = points.length / 2;
const numLineSegments = lines.length / 2 / 2;
</code></pre>
<p>and if we run that</p>
<p><div class="webgl_example_container">
  <iframe class="webgl_example" style=" " src="/webgl/resources/editor.html?url=/webgl/lessons/..%2Fwebgl-gpgpu-closest-line-transformfeedback.html"></iframe>
  <a class="webgl_center" href="/webgl/lessons/../webgl-gpgpu-closest-line-transformfeedback.html" target="_blank">click here to open in a separate window</a>
</div>

</p>
<p>You can bump up the number of points and lines
but at some point you won’t be able to tell which
points go with which lines but with a smaller number
you can at least visually verify it’s working.</p>
<p>Just for fun, lets combine the particle example and this
example. We’ll use the techniques we used to update
the positions of particles to update the points. For
updating the line end points we’ll do what we did at the
top and write results to a texture.</p>
<p>To do that we copy in the <code class="notranslate" translate="no">updatePositionFS</code> vertex shader
from the particle example. For the lines, since their values
are stored in a texture we need to move their points in
a fragment shader</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">const updateLinesVS = `#version 300 es
in vec4 position;
void main() {
  gl_Position = position;
}
`;

const updateLinesFS = `#version 300 es
precision highp float;

uniform sampler2D linesTex;
uniform sampler2D velocityTex;
uniform vec2 canvasDimensions;
uniform float deltaTime;

out vec4 outColor;

vec2 euclideanModulo(vec2 n, vec2 m) {
	return mod(mod(n, m) + m, m);
}

void main() {
  // compute texel coord from gl_FragCoord;
  ivec2 texelCoord = ivec2(gl_FragCoord.xy);
  
  vec2 position = texelFetch(linesTex, texelCoord, 0).xy;
  vec2 velocity = texelFetch(velocityTex, texelCoord, 0).xy;
  vec2 newPosition = euclideanModulo(position + velocity * deltaTime, canvasDimensions);

  outColor = vec4(newPosition, 0, 1);
}
`;
</code></pre>
<p>We can then compile the 2 new shaders for updating the points and
the lines and look up locations</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">+const updatePositionPrg = createProgram(
+    gl, [updatePositionVS, updatePositionFS], ['newPosition']);
+const updateLinesPrg = createProgram(
+    gl, [updateLinesVS, updateLinesFS]);
const closestLinePrg = createProgram(
    gl, [closestLineVS, closestLineFS], ['closestNdx']);
const drawLinesPrg = createProgram(
    gl, [drawLinesVS, drawClosestLinesPointsFS]);
const drawClosestLinesPrg = createProgram(
    gl, [drawClosestLinesVS, drawClosestLinesPointsFS]);
const drawPointsPrg = createProgram(
    gl, [drawPointsVS, drawClosestLinesPointsFS]);

+const updatePositionPrgLocs = {
+  oldPosition: gl.getAttribLocation(updatePositionPrg, 'oldPosition'),
+  velocity: gl.getAttribLocation(updatePositionPrg, 'velocity'),
+  canvasDimensions: gl.getUniformLocation(updatePositionPrg, 'canvasDimensions'),
+  deltaTime: gl.getUniformLocation(updatePositionPrg, 'deltaTime'),
+};
+const updateLinesPrgLocs = {
+  position: gl.getAttribLocation(updateLinesPrg, 'position'),
+  linesTex: gl.getUniformLocation(updateLinesPrg, 'linesTex'),
+  velocityTex: gl.getUniformLocation(updateLinesPrg, 'velocityTex'),
+  canvasDimensions: gl.getUniformLocation(updateLinesPrg, 'canvasDimensions'),
+  deltaTime: gl.getUniformLocation(updateLinesPrg, 'deltaTime'),
+};
const closestLinePrgLocs = {
  point: gl.getAttribLocation(closestLinePrg, 'point'),
  linesTex: gl.getUniformLocation(closestLinePrg, 'linesTex'),
  numLineSegments: gl.getUniformLocation(closestLinePrg, 'numLineSegments'),
};
const drawLinesPrgLocs = {
  linesTex: gl.getUniformLocation(drawLinesPrg, 'linesTex'),
  matrix: gl.getUniformLocation(drawLinesPrg, 'matrix'),
};
const drawClosestLinesPrgLocs = {
  closestNdx: gl.getAttribLocation(drawClosestLinesPrg, 'closestNdx'),
  linesTex: gl.getUniformLocation(drawClosestLinesPrg, 'linesTex'),
  matrix: gl.getUniformLocation(drawClosestLinesPrg, 'matrix'),
  numPoints: gl.getUniformLocation(drawClosestLinesPrg, 'numPoints'),
};
const drawPointsPrgLocs = {
  point: gl.getAttribLocation(drawPointsPrg, 'point'),
  matrix: gl.getUniformLocation(drawPointsPrg, 'matrix'),
  numPoints: gl.getUniformLocation(drawPointsPrg, 'numPoints'),
};
</code></pre>
<p>We need to generate velocities for both the points and lines</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">const points = createPoints(8, [[0, gl.canvas.width], [0, gl.canvas.height]]);
const lines = createPoints(125 * 2, [[0, gl.canvas.width], [0, gl.canvas.height]]);
const numPoints = points.length / 2;
const numLineSegments = lines.length / 2 / 2;

+const pointVelocities = createPoints(numPoints, [[-20, 20], [-20, 20]]);
+const lineVelocities = createPoints(numLineSegments * 2, [[-20, 20], [-20, 20]]);
</code></pre>
<p>We need to make 2 buffers for points, so we can swap them like we did above
for particles. We also need a buffer for the point velocities. And we need
a -1 to +1 clip space quad for updating the line positions.</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">const closestNdxBuffer = makeBuffer(gl, points.length * 4, gl.STATIC_DRAW);
-const pointsBuffer = makeBuffer(gl, new Float32Array(points), gl.STATIC_DRAW);
+const pointsBuffer1 = makeBuffer(gl, new Float32Array(points), gl.DYNAMIC_DRAW);
+const pointsBuffer2 = makeBuffer(gl, new Float32Array(points), gl.DYNAMIC_DRAW);
+const pointVelocitiesBuffer = makeBuffer(gl, new Float32Array(pointVelocities), gl.STATIC_DRAW);
+const quadBuffer = makeBuffer(gl, new Float32Array([
+  -1, -1,
+   1, -1,
+  -1,  1,
+  -1,  1,
+   1, -1,
+   1,  1,
+]), gl.STATIC_DRAW);
</code></pre>
<p>Similarly we now need 2 textures to hold the line end points, and we’ll update
one from the other and swap. And, we need a texture to hold the velocities
for the line end points as well.</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">-const {tex: linesTex, dimensions: linesTexDimensions} =
-    createDataTexture(gl, lines, 2, gl.RG32F, gl.RG, gl.FLOAT);
+const {tex: linesTex1, dimensions: linesTexDimensions1} =
+    createDataTexture(gl, lines, 2, gl.RG32F, gl.RG, gl.FLOAT);
+const {tex: linesTex2, dimensions: linesTexDimensions2} =
+    createDataTexture(gl, lines, 2, gl.RG32F, gl.RG, gl.FLOAT);
+const {tex: lineVelocitiesTex, dimensions: lineVelocitiesTexDimensions} =
+    createDataTexture(gl, lineVelocities, 2, gl.RG32F, gl.RG, gl.FLOAT);
</code></pre>
<p>We need a bunch of vertex arrays.</p>
<ul>
<li>2 for updating positions (one that
takes <code class="notranslate" translate="no">pointsBuffer1</code> as input and another that takes <code class="notranslate" translate="no">pointsBuffer2</code>
as input).</li>
<li>1 to hold the clip space -1 to +1 quad used when updating
the lines.</li>
<li>2 to compute the closest lines (one that looks at points
in <code class="notranslate" translate="no">pointsBuffer1</code> and one that looks at points in <code class="notranslate" translate="no">pointsBuffer2</code>).</li>
<li>2 to draw the points (one that looks at points
in <code class="notranslate" translate="no">pointsBuffer1</code> and one that looks at points in <code class="notranslate" translate="no">pointsBuffer2</code>)</li>
</ul>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">+const updatePositionVA1 = makeVertexArray(gl, [
+  [pointsBuffer1, updatePositionPrgLocs.oldPosition],
+  [pointVelocitiesBuffer, updatePositionPrgLocs.velocity],
+]);
+const updatePositionVA2 = makeVertexArray(gl, [
+  [pointsBuffer2, updatePositionPrgLocs.oldPosition],
+  [pointVelocitiesBuffer, updatePositionPrgLocs.velocity],
+]);
+
+const updateLinesVA = makeVertexArray(gl, [
+  [quadBuffer, updateLinesPrgLocs.position],
+]);

-const closestLinesVA = makeVertexArray(gl, [
-  [pointsBuffer, closestLinePrgLocs.point],
-]);
+const closestLinesVA1 = makeVertexArray(gl, [
+  [pointsBuffer1, closestLinePrgLocs.point],
+]);
+const closestLinesVA2 = makeVertexArray(gl, [
+  [pointsBuffer2, closestLinePrgLocs.point],
+]);

const drawClosestLinesVA = gl.createVertexArray();
gl.bindVertexArray(drawClosestLinesVA);
gl.bindBuffer(gl.ARRAY_BUFFER, closestNdxBuffer);
gl.enableVertexAttribArray(drawClosestLinesPrgLocs.closestNdx);
gl.vertexAttribIPointer(drawClosestLinesPrgLocs.closestNdx, 1, gl.INT, 0, 0);
gl.vertexAttribDivisor(drawClosestLinesPrgLocs.closestNdx, 1);

-const drawPointsVA = makeVertexArray(gl, [
-  [pointsBuffer, drawPointsPrgLocs.point],
-]);
+const drawPointsVA1 = makeVertexArray(gl, [
+  [pointsBuffer1, drawPointsPrgLocs.point],
+]);
+const drawPointsVA2 = makeVertexArray(gl, [
+  [pointsBuffer2, drawPointsPrgLocs.point],
+]);
</code></pre>
<p>We need 2 more transform feedbacks for updating the points</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">function makeTransformFeedback(gl, buffer) {
  const tf = gl.createTransformFeedback();
  gl.bindTransformFeedback(gl.TRANSFORM_FEEDBACK, tf);
  gl.bindBufferBase(gl.TRANSFORM_FEEDBACK_BUFFER, 0, buffer);
  return tf;
}

+const pointsTF1 = makeTransformFeedback(gl, pointsBuffer1);
+const pointsTF2 = makeTransformFeedback(gl, pointsBuffer2);

const closestNdxTF = makeTransformFeedback(gl, closestNdxBuffer);
</code></pre>
<p>We need to make framebuffers for updating the line points, one to
write to <code class="notranslate" translate="no">linesTex1</code> and one to write to <code class="notranslate" translate="no">linesTex2</code></p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">function createFramebuffer(gl, tex) {
  const fb = gl.createFramebuffer();
  gl.bindFramebuffer(gl.FRAMEBUFFER, fb);
  gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, tex, 0);
  return fb;
}

const linesFB1 = createFramebuffer(gl, linesTex1);
const linesFB2 = createFramebuffer(gl, linesTex2);
</code></pre>
<p>Because we want to write to floating point textures and that’s an optional
feature of WebGL2 we need to check if we can by checking for the
<code class="notranslate" translate="no">EXT_color_buffer_float</code> extension</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">// Get A WebGL context
/** @type {HTMLCanvasElement} */
const canvas = document.querySelector(&quot;#canvas&quot;);
const gl = canvas.getContext(&quot;webgl2&quot;);
if (!gl) {
  return;
}
+const ext = gl.getExtension('EXT_color_buffer_float');
+if (!ext) {
+  alert('need EXT_color_buffer_float');
+  return;
+}
</code></pre>
<p>And we need to setup some objects to track current and next so we can
easily swap the things we need to swap each frame</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">let current = {
  // for updating points
  updatePositionVA: updatePositionVA1,  // read from points1
  pointsTF: pointsTF2,                  // write to points2
  // for updating line endings
  linesTex: linesTex1,                  // read from linesTex1
  linesFB: linesFB2,                    // write to linesTex2
  // for computing closest lines
  closestLinesVA: closestLinesVA2,      // read from points2
  // for drawing all lines and closest lines
  allLinesTex: linesTex2,               // read from linesTex2
  // for drawing points
  drawPointsVA: drawPointsVA2,          // read form points2
};

let next = {
  // for updating points
  updatePositionVA: updatePositionVA2,  // read from points2
  pointsTF: pointsTF1,                  // write to points1
  // for updating line endings
  linesTex: linesTex2,                  // read from linesTex2
  linesFB: linesFB1,                    // write to linesTex1
  // for computing closest lines
  closestLinesVA: closestLinesVA1,      // read from points1
  // for drawing all lines and closest lines
  allLinesTex: linesTex1,               // read from linesTex1
  // for drawing points
  drawPointsVA: drawPointsVA1,          // read form points1
};
</code></pre>
<p>Then we need a render loop. Let’s break all the parts
into functions</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">
let then = 0;
function render(time) {
  // convert to seconds
  time *= 0.001;
  // Subtract the previous time from the current time
  const deltaTime = time - then;
  // Remember the current time for the next frame.
  then = time;

  webglUtils.resizeCanvasToDisplaySize(gl.canvas);

  gl.clear(gl.COLOR_BUFFER_BIT);

  updatePointPositions(deltaTime);
  updateLineEndPoints(deltaTime);
  computeClosestLines();

  const matrix = m4.orthographic(0, gl.canvas.width, 0, gl.canvas.height, -1, 1);

  drawAllLines(matrix);
  drawClosestLines(matrix);
  drawPoints(matrix);

  // swap
  {
    const temp = current;
    current = next;
    next = temp;
  }

  requestAnimationFrame(render);
}
requestAnimationFrame(render);
}
</code></pre>
<p>And now we can just fill in the parts. All the previous parts
are the same example we reference <code class="notranslate" translate="no">current</code> at the appropriate places.</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">function computeClosestLines() {
-  gl.bindVertexArray(closestLinesVA);
+  gl.bindVertexArray(current.closestLinesVA);
  gl.useProgram(closestLinePrg);

  gl.activeTexture(gl.TEXTURE0);
-  gl.bindTexture(gl.TEXTURE_2D, linesTex);
+  gl.bindTexture(gl.TEXTURE_2D, current.linesTex);

  gl.uniform1i(closestLinePrgLocs.linesTex, 0);
  gl.uniform1i(closestLinePrgLocs.numLineSegments, numLineSegments);

  drawArraysWithTransformFeedback(gl, closestNdxTF, gl.POINTS, numPoints);
}

function drawAllLines(matrix) {
  gl.bindFramebuffer(gl.FRAMEBUFFER, null);
  gl.viewport(0, 0, gl.canvas.width, gl.canvas.height);

  gl.bindVertexArray(null);
  gl.useProgram(drawLinesPrg);

  // bind the lines texture to texture unit 0
  gl.activeTexture(gl.TEXTURE0);
-  gl.bindTexture(gl.TEXTURE_2D, linesTex);
+  gl.bindTexture(gl.TEXTURE_2D, current.allLinesTex);

  // Tell the shader to use texture on texture unit 0
  gl.uniform1i(drawLinesPrgLocs.linesTex, 0);
  gl.uniformMatrix4fv(drawLinesPrgLocs.matrix, false, matrix);

  gl.drawArrays(gl.LINES, 0, numLineSegments * 2);
}

function drawClosestLines(matrix) {
  gl.bindVertexArray(drawClosestLinesVA);
  gl.useProgram(drawClosestLinesPrg);

  gl.activeTexture(gl.TEXTURE0);
-  gl.bindTexture(gl.TEXTURE_2D, linesTex);
+  gl.bindTexture(gl.TEXTURE_2D, current.allLinesTex);

  gl.uniform1i(drawClosestLinesPrgLocs.linesTex, 0);
  gl.uniform1f(drawClosestLinesPrgLocs.numPoints, numPoints);
  gl.uniformMatrix4fv(drawClosestLinesPrgLocs.matrix, false, matrix);

  gl.drawArraysInstanced(gl.LINES, 0, 2, numPoints);
}

function drawPoints(matrix) {
-  gl.bindVertexArray(drawPointsVA);
+  gl.bindVertexArray(current.drawPointsVA);
  gl.useProgram(drawPointsPrg);

  gl.uniform1f(drawPointsPrgLocs.numPoints, numPoints);
  gl.uniformMatrix4fv(drawPointsPrgLocs.matrix, false, matrix);

  gl.drawArrays(gl.POINTS, 0, numPoints);
}
</code></pre>
<p>And we need 2 new functions for updating the points and lines</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">function updatePointPositions(deltaTime) {
  gl.bindVertexArray(current.updatePositionVA);
  gl.useProgram(updatePositionPrg);
  gl.uniform1f(updatePositionPrgLocs.deltaTime, deltaTime);
  gl.uniform2f(updatePositionPrgLocs.canvasDimensions, gl.canvas.width, gl.canvas.height);
  drawArraysWithTransformFeedback(gl, current.pointsTF, gl.POINTS, numPoints);
}

function updateLineEndPoints(deltaTime) {
  // Update the line endpoint positions ---------------------
  gl.bindVertexArray(updateLinesVA); // just a quad
  gl.useProgram(updateLinesPrg);

  // bind texture to texture units 0 and 1
  gl.activeTexture(gl.TEXTURE0);
  gl.bindTexture(gl.TEXTURE_2D, current.linesTex);
  gl.activeTexture(gl.TEXTURE0 + 1);
  gl.bindTexture(gl.TEXTURE_2D, lineVelocitiesTex);

  // tell the shader to look at the textures on texture units 0 and 1
  gl.uniform1i(updateLinesPrgLocs.linesTex, 0);
  gl.uniform1i(updateLinesPrgLocs.velocityTex, 1);
  gl.uniform1f(updateLinesPrgLocs.deltaTime, deltaTime);
  gl.uniform2f(updateLinesPrgLocs.canvasDimensions, gl.canvas.width, gl.canvas.height);

  // write to the other lines texture
  gl.bindFramebuffer(gl.FRAMEBUFFER, current.linesFB);
  gl.viewport(0, 0, ...lineVelocitiesTexDimensions);

  // drawing a clip space -1 to +1 quad = map over entire destination array
  gl.drawArrays(gl.TRIANGLES, 0, 6);
}
</code></pre>
<p>And with that we can see it working dynamically and all the computation
is happening on the GPU</p>
<p><div class="webgl_example_container">
  <iframe class="webgl_example" style=" " src="/webgl/resources/editor.html?url=/webgl/lessons/..%2Fwebgl-gpgpu-closest-line-dynamic-transformfeedback.html"></iframe>
  <a class="webgl_center" href="/webgl/lessons/../webgl-gpgpu-closest-line-dynamic-transformfeedback.html" target="_blank">click here to open in a separate window</a>
</div>

</p>
<h2 id="some-caveats-about-gpgpu">Some Caveats about GPGPU</h2>
<ul>
<li>
<p>GPGPU in WebGL1 is mostly limited to using 2D arrays as output (textures).
WebGL2 adds the ability to just process a 1D array of arbitrary size via
transform feedback.</p>
<p>If you’re curious see <a href="https://webglfundamentals.org/webgl/lessons/webgl-gpgpu.html">the same article for webgl1</a> to see how all of these were done using only the ability
to output to textures. Of course with a little thought that should be obvious.</p>
<p>WebGL2 versions using textures instead of transform feedback are available as well
since using <code class="notranslate" translate="no">texelFetch</code> and having more texture formats available slightly changes
their implementations.</p>
<ul>
<li><a href="../webgl-gpgpu-particles.html">particles</a></li>
<li><a href="../webgl-gpgpu-closest-line-results.html">closest lines results</a></li>
<li><a href="../webgl-gpgpu-closest-line.html">closest lines visualized</a></li>
<li><a href="../webgl-gpgpu-closest-line-dynamic.html">closest lines dynamic</a></li>
</ul>
</li>
<li>
<p>Firefox Bug<a id="firefox-bug"></a></p>
<p>Firefox as of version 84 has <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1677552">a bug</a> in that
it wrongly requires there to be at least one active attribute that uses a divisor of 0 when calling
<code class="notranslate" translate="no">drawArraysIndexed</code>. That means the example above where we draw the closest lines using
<code class="notranslate" translate="no">drawArraysIndexed</code> fails.</p>
<p>To work around it we can create a buffer that just has <code class="notranslate" translate="no">[0, 1]</code> in it and use that
on an attribute for how we used <code class="notranslate" translate="no">gl_VertexID % 2</code>. Instead we’d use</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-glsl">in int endPoint;  // needed by firefox

...
-int linePointId = closestNdx * 2 + gl_VertexID % 2;
+int linePointId = closestNdx * 2 + endPoint;
...
</code></pre>
<p>which will <a href="../webgl/webgl-gpgpu-closest-line-dynamic-transformfeedback-ff.html">make it work in firefox</a>.</p>
</li>
<li>
<p>GPUs don’t have the same precision as CPUs.</p>
<p>Check your results and make sure they are acceptable.</p>
</li>
<li>
<p>There is overhead to GPGPU.</p>
<p>In the first few examples above we computed some
data using WebGL and then read the results. Setting up buffers and textures,
setting attributes and uniforms takes time. Enough time that for anything
under a certain size it would be better to just do it in JavaScript.
The actual examples multiplying 6 numbers or adding 3 pairs of numbers
are much too small for GPGPU to be useful. Where that trade off is
is undefined. Experiment but just a guess that if you’re not doing at least
1000 or more things keep it in JavaScript</p>
</li>
<li>
<p><code class="notranslate" translate="no">readPixels</code> and <code class="notranslate" translate="no">getBufferSubData</code> are slow</p>
<p>Reading the results from WebGL is slow so it’s important to avoid it
as much as possible. As an example neither the particle system above nor
the dynamic closest lines example ever
read the results back to JavaScript. Where you can, keep the results
on the GPU for as long as possible. In other words, you could do something
like</p>
<ul>
<li>compute stuff on GPU</li>
<li>read result</li>
<li>prep result for next step</li>
<li>upload prepped result to gpu</li>
<li>compute stuff on GPU</li>
<li>read result</li>
<li>prep result for next step</li>
<li>upload prepped result to gpu</li>
<li>compute stuff on GPU</li>
<li>read result</li>
</ul>
<p>whereas via creative solutions it would be much faster if you could</p>
<ul>
<li>compute stuff on GPU</li>
<li>prep result for next step using GPU</li>
<li>compute stuff on GPU</li>
<li>prep result for next step using GPU</li>
<li>compute stuff on GPU</li>
<li>read result</li>
</ul>
<p>Our dynamic closest lines example did this. The results never leave
the GPU.</p>
<p>As another example I once wrote a histogram computing shader. I then read
the results back into JavaScript, figured out the min and max values
Then drew the image back to the canvas using those min and max values
as uniforms to auto-level the image.</p>
<p>But, it turned instead of reading the histogram back into JavaScript
I could instead run a shader on the histogram itself that generated
a 2 pixel texture with the min and max values in the texture.</p>
<p>I could then pass that 2 pixel texture into the 3rd shader which it
could read for the min and max values. No need to read them out of the
GPU for setting uniforms.</p>
<p>Similarly to display the histogram itself I first read the histogram
data from the GPU but later I instead wrote a shader that could
visualize the histogram data directly removing the need to read it
back to JavaScript.</p>
<p>By doing that the entire process stayed on the GPU and was likely much
faster.</p>
</li>
<li>
<p>GPUs can do many things in parallel but most can’t multi-task the same way
a CPU can. GPUs usually can’t do “<a href="https://www.google.com/search?q=preemptive+multitasking">preemptive multitasking</a>”.
That means if you give them a very complex shader that say takes 5 minutes to
run they’ll potentially freeze your entire machine for 5 minutes.
Most well made OSes deal with this by having the CPU check how long it’s been
since the last command they gave to the GPU. If it’s been too long (5-6 second)
and the GPU has not responded then their only option is to reset the GPU.</p>
<p>This is one reason why WebGL can <em>lose the context</em> and you get an “Aw, rats!”
or similar message.</p>
<p>It’s easy to give the GPU too much to do but in graphics it’s not <em>that</em>
common to take it to the 5-6 second level. It’s usually more like the 0.1
second level which is still bad but usually you want graphics to run fast
and so the programmer will hopefully optimize or find a different technique
to keep the their app responsive.</p>
<p>GPGPU on the other hand you might truly want to give the GPU a heavy task
to run. There is no easy solution here. A mobile phone has a much less powerful
GPU than a top end PC. Other than doing your own timing there is no way to
know for sure how much work you can give a GPU before its “too slow”</p>
<p>I don’t have a solution to offer. Only a warning that depending on what you’re
trying to do you may run into that issue.</p>
</li>
<li>
<p>Mobile devices don’t generally support rendering to floating point textures</p>
<p>There are various ways of working around the issue. One use you can
use the GLSL functions <code class="notranslate" translate="no">floatBitsToInt</code>, <code class="notranslate" translate="no">floatBitsToUint</code>, <code class="notranslate" translate="no">IntBitsToFloat</code>,
and <code class="notranslate" translate="no">UintBitsToFloat</code>.</p>
<p>As an example, <a href="../webgl-gpgpu-particles.html">the texture based version of the particle example</a>
needs to write to floating point textures. We could fix it so it doesn’t require them by
declaring our texture to be type <code class="notranslate" translate="no">RG32I</code> (32 integer textures) but still
upload floats.</p>
<p>In the shader we’d need to read the textures as integers and decode them
to floats and then encode the result back into integers. For example</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-glsl">#version 300 es
precision highp float;

-uniform highp sampler2D positionTex;
-uniform highp sampler2D velocityTex;
+uniform highp isampler2D positionTex;
+uniform highp isampler2D velocityTex;
uniform vec2 canvasDimensions;
uniform float deltaTime;

out ivec4 outColor;

vec2 euclideanModulo(vec2 n, vec2 m) {
	return mod(mod(n, m) + m, m);
}

void main() {
  // there will be one velocity per position
  // so the velocity texture and position texture
  // are the same size.

  // further, we're generating new positions
  // so we know our destination is the same size
  // as our source

  // compute texcoord from gl_FragCoord;
  ivec2 texelCoord = ivec2(gl_FragCoord.xy);
  
-  vec2 position = texelFetch(positionTex, texelCoord, 0).xy;
-  vec2 velocity = texelFetch(velocityTex, texelCoord, 0).xy;
+  vec2 position = intBitsToFloat(texelFetch(positionTex, texelCoord, 0).xy);
+  vec2 velocity = intBitsToFloat(texelFetch(velocityTex, texelCoord, 0).xy);
  vec2 newPosition = euclideanModulo(position + velocity * deltaTime, canvasDimensions);

-  outColor = vec4(newPosition, 0, 1);
+  outColor = ivec4(floatBitsToInt(newPosition), 0, 1);
}
</code></pre>
<p><a href="../webgl-gpgpu-particles-no-floating-point-textures.html">Here’s a working example</a></p>
</li>
</ul>
<p>I hope these examples helped you understand the key idea of GPGPU in WebGL
is just the fact that WebGL reads from and writes to arrays of <strong>data</strong>,
not pixels.</p>
<p>Shaders work similar to <code class="notranslate" translate="no">map</code> functions in that the function being called
for each value doesn’t get to decide where its value will be stored.
Rather that is decided from outside the function. In WebGL’s case
that’s decided by how you setup what you’re drawing. Once you call <code class="notranslate" translate="no">gl.drawXXX</code>
the shader will be called for each needed value being asked “what value should
I make this?”</p>
<p>And that’s really it.</p>
<hr>
<p>Since we made some particles via GPGPU there is <a href="https://www.youtube.com/watch?v=X-iSQQgOd1A">this wonderful video</a> which in its second half
uses compute shaders to do a “slime” simulation.</p>
<p>Using the techniques above <a href="https://jsgist.org/?src=94e9058c7ef1a4f124eccab4e7fdcd1d">here it is translated into WebGL2</a>.</p>

    </div>
    <div class="lesson-sidebar">
        <select class="language">
    <option value="/webgl/lessons/webgl-gpgpu.html" selected>English</a>
    <option value="/webgl/lessons/de/webgl-gpgpu.html" >Deutsch</a>
    <option value="/webgl/lessons/ja/webgl-gpgpu.html" >日本語</a>
    <option value="/webgl/lessons/ko/webgl-gpgpu.html" >한국어</a>
    <option value="/webgl/lessons/pt-br/webgl-gpgpu.html" >Português Brasileiro</a>
    <option value="/webgl/lessons/ru/webgl-gpgpu.html" >Русский</a>
    <option value="/webgl/lessons/zh_cn/webgl-gpgpu.html" >简体中文</a>
</select>


        <div id="toc">
          <ul>  <li>Fundamentals</li>
        <ul>
          <li><a href="/webgl/lessons/webgl-getting-webgl2.html">How to use WebGL2</a></li>
<li><a href="/webgl/lessons/webgl-fundamentals.html">Fundamentals</a></li>
<li><a href="/webgl/lessons/webgl-how-it-works.html">How It Works</a></li>
<li><a href="/webgl/lessons/webgl-shaders-and-glsl.html">Shaders and GLSL</a></li>
<li><a href="/webgl/lessons/resources/webgl-state-diagram.html">WebGL2 State Diagram</a></li>
        </ul>
  <li>WebGL2 vs WebGL1</li>
        <ul>
          <li><a href="/webgl/lessons/webgl2-whats-new.html">What's new in WebGL2</a></li>
<li><a href="/webgl/lessons/webgl1-to-webgl2.html">Moving from WebGL1 to WebGL2</a></li>
<li><a href="/webgl/lessons/webgl1-to-webgl2-fundamentals.html">Differences from WebGLFundamentals.org to WebGL2Fundamentals.org</a></li>
        </ul>
  <li>Image Processing</li>
        <ul>
          <li><a href="/webgl/lessons/webgl-image-processing.html">Image Processing</a></li>
<li><a href="/webgl/lessons/webgl-image-processing-continued.html">Image Processing Continued</a></li>
        </ul>
  <li>2D translation, rotation, scale, matrix math</li>
        <ul>
          <li><a href="/webgl/lessons/webgl-2d-translation.html">2D Translation</a></li>
<li><a href="/webgl/lessons/webgl-2d-rotation.html">2D Rotation</a></li>
<li><a href="/webgl/lessons/webgl-2d-scale.html">2D Scale</a></li>
<li><a href="/webgl/lessons/webgl-2d-matrices.html">2D Matrices</a></li>
        </ul>
  <li>3D</li>
        <ul>
          <li><a href="/webgl/lessons/webgl-3d-orthographic.html">Orthographic 3D</a></li>
<li><a href="/webgl/lessons/webgl-3d-perspective.html">3D Perspective</a></li>
<li><a href="/webgl/lessons/webgl-3d-camera.html">3D - Cameras</a></li>
<li><a href="/webgl/lessons/webgl-matrix-naming.html">3D - Matrix Naming</a></li>
        </ul>
  <li>Lighting</li>
        <ul>
          <li><a href="/webgl/lessons/webgl-3d-lighting-directional.html">Directional Lighting</a></li>
<li><a href="/webgl/lessons/webgl-3d-lighting-point.html">Point Lighting</a></li>
<li><a href="/webgl/lessons/webgl-3d-lighting-spot.html">Spot Lighting</a></li>
        </ul>
  <li>Structure and Organization</li>
        <ul>
          <li><a href="/webgl/lessons/webgl-less-code-more-fun.html">Less Code, More Fun</a></li>
<li><a href="/webgl/lessons/webgl-drawing-multiple-things.html">Drawing Multiple Things</a></li>
<li><a href="/webgl/lessons/webgl-scene-graph.html">Scene Graphs</a></li>
        </ul>
  <li>Geometry</li>
        <ul>
          <li><a href="/webgl/lessons/webgl-3d-geometry-lathe.html">3D Geometry - Lathe</a></li>
<li><a href="/webgl/lessons/webgl-load-obj.html">Loading .obj files</a></li>
<li><a href="/webgl/lessons/webgl-load-obj-w-mtl.html">Loading .obj w .mtl files</a></li>
        </ul>
  <li>Textures</li>
        <ul>
          <li><a href="/webgl/lessons/webgl-3d-textures.html">Textures</a></li>
<li><a href="/webgl/lessons/webgl-data-textures.html">Data Textures</a></li>
<li><a href="/webgl/lessons/webgl-2-textures.html">Using 2 or More Textures</a></li>
<li><a href="/webgl/lessons/webgl-cors-permission.html">Cross Origin Images</a></li>
<li><a href="/webgl/lessons/webgl-3d-perspective-correct-texturemapping.html">Perspective Correct Texture Mapping</a></li>
<li><a href="/webgl/lessons/webgl-planar-projection-mapping.html">Planar and Perspective Projection Mapping</a></li>
        </ul>
  <li>Rendering To A Texture</li>
        <ul>
          <li><a href="/webgl/lessons/webgl-render-to-texture.html">Render to Texture</a></li>
        </ul>
  <li>Shadows</li>
        <ul>
          <li><a href="/webgl/lessons/webgl-shadows.html">Shadows</a></li>
        </ul>
  <li>Techniques</li>
        <ul>
            <li>2D</li>
        <ul>
          <li><a href="/webgl/lessons/webgl-2d-drawimage.html">2D - DrawImage</a></li>
<li><a href="/webgl/lessons/webgl-2d-matrix-stack.html">2D - Matrix Stack</a></li>
<li><a href="/webgl/lessons/webgl-sprites.html">Sprites</a></li>
        </ul>
  <li>3D</li>
        <ul>
          <li><a href="/webgl/lessons/webgl-cube-maps.html">Cubemaps</a></li>
<li><a href="/webgl/lessons/webgl-environment-maps.html">Environment maps</a></li>
<li><a href="/webgl/lessons/webgl-skybox.html">Skyboxes</a></li>
<li><a href="/webgl/lessons/webgl-skinning.html">Skinning</a></li>
<li><a href="/webgl/lessons/webgl-fog.html">Fog</a></li>
<li><a href="/webgl/lessons/webgl-picking.html">Picking (clicking on stuff)</a></li>
        </ul>
  <li>Text</li>
        <ul>
          <li><a href="/webgl/lessons/webgl-text-html.html">Text - HTML</a></li>
<li><a href="/webgl/lessons/webgl-text-canvas2d.html">Text - Canvas 2D</a></li>
<li><a href="/webgl/lessons/webgl-text-texture.html">Text - Using a Texture</a></li>
<li><a href="/webgl/lessons/webgl-text-glyphs.html">Text - Using a Glyph Texture</a></li>
        </ul>
  <li>GPGPU</li>
        <ul>
          <li><a href="/webgl/lessons/webgl-gpgpu.html">GPGPU</a></li>
        </ul>
        </ul>
  <li>Tips</li>
        <ul>
          <li><a href="/webgl/lessons/webgl-smallest-programs.html">Smallest Programs</a></li>
<li><a href="/webgl/lessons/webgl-drawing-without-data.html">Drawing Without Data</a></li>
<li><a href="/webgl/lessons/webgl-shadertoy.html">Shadertoy</a></li>
<li><a href="/webgl/lessons/webgl-pulling-vertices.html">Pulling Vertices</a></li>
        </ul>
  <li>Optimization</li>
        <ul>
          <li><a href="/webgl/lessons/webgl-indexed-vertices.html">Indexed Vertices (gl.drawElements)</a></li>
<li><a href="/webgl/lessons/webgl-instanced-drawing.html">Instanced Drawing</a></li>
        </ul>
  <li>Misc</li>
        <ul>
          <li><a href="/webgl/lessons/webgl-setup-and-installation.html">Setup And Installation</a></li>
<li><a href="/webgl/lessons/webgl-boilerplate.html">Boilerplate</a></li>
<li><a href="/webgl/lessons/webgl-resizing-the-canvas.html">Resizing the Canvas</a></li>
<li><a href="/webgl/lessons/webgl-animation.html">Animation</a></li>
<li><a href="/webgl/lessons/webgl-points-lines-triangles.html">Points, Lines, and Triangles</a></li>
<li><a href="/webgl/lessons/webgl-multiple-views.html">Multiple Views, Multiple Canvases</a></li>
<li><a href="/webgl/lessons/webgl-visualizing-the-camera.html">Visualizing the Camera</a></li>
<li><a href="/webgl/lessons/webgl-and-alpha.html">WebGL2 and Alpha</a></li>
<li><a href="/webgl/lessons/webgl-2d-vs-3d-library.html">2D vs 3D libraries</a></li>
<li><a href="/webgl/lessons/webgl-anti-patterns.html">Anti-Patterns</a></li>
<li><a href="/webgl/lessons/webgl-matrix-vs-math.html">WebGL2 Matrices vs Math Matrices</a></li>
<li><a href="/webgl/lessons/webgl-precision-issues.html">Precision Issues</a></li>
<li><a href="/webgl/lessons/webgl-tips.html#screenshot">Taking a screenshot</a></li>
<li><a href="/webgl/lessons/webgl-tips.html#preservedrawingbuffer">Prevent the Canvas Being Cleared</a></li>
<li><a href="/webgl/lessons/webgl-tips.html#tabindex">Get Keyboard Input From a Canvas</a></li>
<li><a href="/webgl/lessons/webgl-tips.html#html-background">Use WebGL2 as Background in HTML</a></li>
<li><a href="/webgl/lessons/webgl-cross-platform-issues.html">Cross Platform Issues</a></li>
<li><a href="/webgl/lessons/webgl-qna.html">Questions and Answers</a></li>
        </ul>
  <li>Reference</li>
        <ul>
          <li><a href="/webgl/lessons/webgl-attributes.html">Attributes</a></li>
<li><a href="/webgl/lessons/webgl-texture-units.html">Texture Units</a></li>
<li><a href="/webgl/lessons/webgl-framebuffers.html">Framebuffers</a></li>
<li><a href="/webgl/lessons/webgl-readpixels.html">readPixels</a></li>
<li><a href="/webgl/lessons/webgl-references.html">References</a></li>
        </ul></ul>
<ul>
  <li><a href="/docs/">Helper API Docs</a></li>
  <li><a href="https://twgljs.org">TWGL, A tiny WebGL helper library</a></li>
  <li><a href="https://github.com/gfxfundamentals/webgl2-fundamentals">github</a></li>
</ul>
        </div>
    </div>
    <div class="lesson-comments">
        
<div>Issue/Bug? <a href="https://github.com/gfxfundamentals/webgl2-fundamentals/issues">Create an issue on github</a>.</div>
<div class="lesson-comment-notes">
   Use <b>&lt;pre&gt;&lt;code&gt;</b>code goes here<b>&lt;/code&gt;&lt;/pre&gt;</b> for code blocks
</div>
  

        <div id="disqus_thread"></div>
        <script>
            /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
            var disqus_shortname = 'webgl2fundamentals'; // required: replace example with your forum shortname
            var disqus_identifier = 'WebGL2 GPGPU';
            var disqus_title = 'WebGL2 GPGPU';

            /* * * DON'T EDIT BELOW THIS LINE * * */
            (function() {
                if (window.location.hostname.indexOf("webgl2fundamentals.org") < 0) {
                    return;
                }
                var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
                dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
                (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
            })();
        </script>
        <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
        <a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    </div>
  </div>
</div>
</body>
<script>
const settings = {
  contribTemplate: "Thank you <a href=\"${html_url}\"><img src=\"${avatar_url}\"> ${login}</a><br>for <a href=\"https://github.com/${owner}/${repo}/commits?author=${login}\">${contributions} contributions</a>",
  owner: "gfxfundamentals",
  repo: "webgl2-fundamentals",
};
</script>
<script src="/contributors.js"></script>
<script src="/3rdparty/jquery-1.11.2.min.js"></script>
<script src="/webgl/lessons/resources/prettify.js"></script>
<script src="/webgl/lessons/resources/lesson.js" type="module"></script>
<script>
</script>


</html>



